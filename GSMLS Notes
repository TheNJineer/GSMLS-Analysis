PRIORITIES:
1) NJTaxAssessment
***Figure out how to properly add a package to sys.path and use it. Currently copied class from parent folder
***The url's arent https even though thats what I'm labeling them as. Figure this out. I think I need to add verifyssl=False
- Update city_database function
- Complete the code to stream Essex County property dbs (DONE)
    - The download_link isnt present sometimes and presents an error
    - Generate a different proxy then load webpage using city id (?town=0711), dont click the radio buttons anymore
    - Be sure to update the format_proxies function when done in the main file
    - May need to create a function loop to try different proxies until the download initiates
    - Use SeleniumWire to intercept some of the driver requests to read/change the payloads to get the dbs I need
- Clean the municipality databases (DONE)
    - Create uniformity in the 'Property Location' column by changing all abbreviated street names to the full endings (DONE)
    - Create function called (?)
        - Create uniformity in the 'Property Location' column by changing all
        abbreviated number block (1st, 2nd, 3rd, etc) to fully spelled
        - I dont want to make the changes in either the tax_db or GSMLS_db permenant so create copies then apply the function
23) create decorator for nj_databases to create a time constraint for downloads (1 year)

2) GSMLS
***CHECKPOINT: Finish sq_ft_keyerror and separating the property_archive function into smaller functions
               Make sure rpr and rpr_sq_ft actually works with real addresses and what happens if the address isnt found
****Is there an easier, quicker way to create the farm area dictionary?
- Work on potential_farm_area() (DONE)
- Separate property_archive function into smaller functions
- turn the street-ending search from sq_ft_keyerror() into a separate function to use on changing the tax and mls_dbs (NOT NECESSARY)
    - The current method changes every instance of the pattern found instead of the last one (NOT NECESSARY)
- elif final_address[:10].upper() in outer_address_list doesnt work because its checking the list to see if that actual value is in the list
    - I have to create a for loop and check if the slice is in each individual value (DONE)
    - *** The only thing I can think of is that the address isnt cleaned and it has that weird html space in it (DONE)
- Refactor the property_archive() function to produce the property listing history
- Create separate functions for the KeyError and ValueError exceptions in sq_ft_search (DONE)
- The addresses in the address_list of sq_ft_search need to be cleaned before used. They have weird binary text in them (DONE)
    - Use the code in the addy section of the KeyError to create a new function (DONE)
    - {'50\xa0Little York Mt. Pleasant', '50\xa0LT YORK-MT PLEASANT RD', '50\xa0Little York Mt  Pleasant'}
- For files that dont end in 'GSMLS', they will cause an error. Create a way to add 'GSMLS' to the end (DONE)
- Add a column named 'MLS' to the target db and have the value equal to the DB it came from (DONE)
- Finish sq_ft_finder address conversion (DONE)
- Add a column named 'Variance Needed' in the LND db columns (DONE)
- Add try-except block in sq_ft_finder to accept KeyError if the address doesnt exist is the tax_db (DONE)
    - Add a function which looks into GSMLS Property Archive tab for alternate address spelling if address isnt found in the tax_db (DONE)
    1) Login (DONE)
    2) Type address into main search bar (DONE)
    3) click the mls id which matches ours (DONE)
    4) New window pops out, see how to capture this (DONE)
    5) Click Property Archive. New window pops out, see how to capture this (DONE)
    6) Scrap the table from the page and log out (DONE)
    7) Create a list from addresses from the table (DONE)
    8) If table address == target address, continue (DONE)
    9) Else, if table address in tax_db['Property Location'].tolist() (DONE)
    10) If it doesnt work, continue (DONE)
    11) Else return that address to be used in the recursive sq_ft_search (DONE)

    - Add a function which looks into RPR if none of the property archive addresses work (DONE)
- Add try-except block for ValueError where the tax_db has duplicate addresses. (DONE)
The tax_db.loc[address.upper(), 'Sq. Ft.'] will return a series, not a specific value (DONE)
- Extend the pattern search for convert_lot_size()
    - Land acres pattern needs to inlcude IRR, and all other abrv
- Addresses still need extra cleaning. These addresses were manually input and could have hidden errors (extra sapces, etc) (DONE)
- Create a function called (?) which is used inside of sq_ft_finder() which actually does the transformation. Use in each if-elif block (DONE)
- Figure out how to automate the operation of the macro immediately after download and dispose of the old files
- Create a anew directory called 'GSMLS' in the Selenium Temp Folder to put downloads in. Switch to this directory in the main function
- Consolidate the 'MUL' and 'LND' quarterly_sales function into one. Accept property_type as an arg to use as a switch case
    - Modify the decorator to insert the property type as an arg
- Create a try-except block in the main function which can be used to restart the program recursively
- Refactor the main() function to not login to GSMLS if theres not data to download
- Use Funct.tools to get the proper names for the function when going through the decorators
- A selenium TimeoutError can occur if a page element isnt found. How to I get around this to continue the program?
_ Refactor the run_main decorator to run on a quarterly basis
    - uses a shelve file to know which dates to download for
- Fix the clean_and_transform function:
    - Round the BATHSTOTAL column to one dec place
    - SPLP should be rounded to 3 decimal places
- *** Create function to store all qtrly results in SQL after cleaning the data
    - Use the clean_db() and new pandas2sql()
- Track rental prices as well

3) Complete lat_long function in GSMLS
    ****** Maybe shift to the GSMLS to use inside DealAnalyzer modules. (DONE)
    Only run function when analyzing distance instead of running the risk of getting banded for webscrapping
    ***The lat_long results should be immediately put back into SQL as a table update
    - The function will take the file as an arg and convert into Pandas db
    - Add Request module exceptions to the function
    - add logic for if county and or city vars arent None. Could be str or list types
    - Be sure to throttle the program by 1 sec after every request (DONE)
        - Build in a function to detect 400 and 500 level responses and adjust after
            - Use a While loop to continue running that address if 400 or 500 level responses are given
    - Delete all of the Selenium code and replace with Request and BS4 module syntax (DONE)
    - Track the 'importance' key of the JSON file. May depict the accuracy of the location (DONE)
- Run descriptive statistics for all cities: max, min, mean, median, mode, stddev and quartiles
- Create function which creates email campaigns for specific counties and cities based on analysis results (adjusted every qtr)
- *** Create a script that is solely run to download the quarterly sales results for RES, MUL, and LND properties
- *** Create a script that is solely run to clean and transform the data to be stored in SQL databases

4) Complete MachineLearning script
5) Start the DealAnalysis script
- Continually check if MLS deals are still available. Notice status changes
- Composite class (will use NJTaxAssessment, Foreclosures, GSMLS and MachineLearning
6) Complete HomeDepot Scrapper and Analysis
7) Complete Foreclosures script
8) NJ Planning Board Scraper
- Can I set up a REST API to check when each board is updated to then scrape?

NJTaxAssessment
________________________________________________________________________________
17) Add logger messages to necessary parts of the NJTaxAssessment code
20) Stream the zip file instead of downloading to reduce the built-in latency
    - Use the Requests ans Session.Requests module to stream the files. (ie: Scraper class) (PARTIALLY DONE)
    - Update the stream_zipfile function args to download_param= None, payload= None (is this still necessary?)
        - do if statement blocks that are executed based on the arg provided to the function
    - Needs to be implemented for the Essex County function (STREAMING EACH FILE CURRENTLY CANT BE DONE)
    *****There's a download limit on the website. Switch code to download all municipalities at one time
        - Build a Selenium latency to wait for download to finish (DONE)
        - Find a way to match the city with the downloaded file (NOT NECESSARY)
        **** Cookies wont let me download the file more than once. Download limit
            - Build in a timestamp method essex county scrape and timestamp= None arg into unzip and extract (DONE)
            If timestamp not None its automatically an Essex county file (DONE)
            If the delta between the timestamp and file download is less than X sec then name and move file, else continue
            - Can Python show metadata of a file? (DONE)
***21) Refactor city_database to open the "All Municipalities" xlsx for ESSEX county cities which dont have dbs
    - HOLD OFF ON THIS AS LAST RESORT
    - This code could present future errors for counties which have duplicate city spellings. Fix this
    - This file will only be used for cities which dont have DBs
5) Continue working on the long_lat function
    - Change the filename variable syntax so the files can be found
    - Create a db cleaning function to use inside lat_long
    - Change the sheet name during the db save to overwrite the first sheet

7)Foreclosure
____________________________________________________________________________________________________
    *** I want to store this as a SQL DB. This script will automatically check the site every week to update the status of the properties in the
    db. After X amount of time after the sale of the property, the SQL DB will delete that entry. And add new ones if they already dont exist
16) Alter the NJTaxAssessment class for the nj_databases to find the db for one county and one city as well
    - Create an arg entry for 'county' and 'city' in nj_databases
    - Create an arg entry for 'county' and 'city' in all_county_scrape
    - Create an arg entry for 'city' in essex_county_scrape
    ****Allow for str or list objects in these functions and alter the logic based on the object
    - Add 'if county is None, elif county is not None and city is None, elif county is not None and city is not None' in
        - all_county_scrape
        - nj_databases
    - Add 'if city is None, elif city is not None
18) Allow code to check what was downloaded already and start at new point
8) Continue working on the auction_locations function
    - Save this as a class variable

GSMLS class
________________________________________________________________________________________________________________________
    - Break quarterly_sales_res down into smaller/modular functions
    - Create a function which finds the recently downloaded file and move it to a specific folder, Use NJTaxAssessment function as a template
    - For quarterly sales_res
        Create function for:
        Create a function that asks the user which counties and cities they want to download for to
        account for cities and counties values as NONE
        - no county name(s) or city(s) provided (DONE)
        - one county name no city name
        - list of county names no city names
        - list of county names and list of names
    - Stream the xlsx file instead of downloading to reduce the built-in latency
        - Use the Requests an Session.Requests module to stream the files. (ie: Scraper class)
        - On the final download page, use the Elements and Network tabs to fill out the payload to stream the file

_______________________________________________________________________________________________________________________
Unassigned
3) Continue working on the property_tax_legend function
    - Create an excel sheet which will hold all the data
    - Use Regex to read the values of the cell and produce the values for the new column
9) Continue working on the haversine function
10) This is a program which will require the use of an SQL database
    Create a method which will transfer all of this data to PostgreSQL
11) Create a function which accepts the county and city as args, finds the latest downloaded zip (DONE)
    extracts the file and saves it as the city name in the county directory (DONE)
    11a) This should be a threaded operation. Create an empty list at the top of nj_database to store threaded operations (DONE)
14) Update waiting function
15) Update run_main decorator

Use when you want to implement threading
ALL COUNTYS
# download_link1 = driver_var.find_element(By.XPATH, "/html/body/form/b[2]/big/a")
# download_link1.click()  # Step 5: Download the zip file
# threadobj = threading.Thread(target=NJTaxAssessment.unzip_and_extract,
#                              args=[counties[key], cities[k], download_link.split('/')[2]])  # Step 6: Unzip and save file
# started_threads.append(threadobj)
# threadobj.start()

ESSEX COUNTY
# threadobj = threading.Thread(target=NJTaxAssessment.unzip_and_extract,
#                              args=['ESSEX', cities[k]])  # Step 6: Unzip and save file
# started_threads.append(threadobj)
# threadobj.start()

except ElementNotVisibleException as ENV:  # Make more specific exception handling blocks later
    logger.exception(f'{ENV}')

except ElementNotSelectableException as ENS:
    logger.exception(f'{ENS}')

except NoSuchElementException as NSEE:
    logger.exception(f'{NSEE}')

except WebDriverException as WDE:
    logger.exception(f'{traceback.format_tb(WDE.__traceback__)}')
    GSMLS.sign_out(driver_var)

else:

label[title='10 - Atlantic']

Traceback (most recent call last):
  File "F:\Python 2.0\PyCharm Community Edition 2022.2.1\plugins\python-ce\helpers\pydev\pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Python 2.0\PyCharm Community Edition 2022.2.1\plugins\python-ce\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "F:/Python 2.0/Projects/Real Life Projects/Real Estate Analysis/GSMLS.py", line 1117, in <module>
    obj.main()
  File "F:/Python 2.0/Projects/Real Life Projects/Real Estate Analysis/GSMLS.py", line 1109, in main
    GSMLS.quarterly_sales_mul(driver)
  File "F:/Python 2.0/Projects/Real Life Projects/Real Estate Analysis/GSMLS.py", line 69, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:/Python 2.0/Projects/Real Life Projects/Real Estate Analysis/GSMLS.py", line 714, in quarterly_sales_mul
    GSMLS.results_found(driver_var, cities[city_id], qtr, 'MUL')
  File "F:/Python 2.0/Projects/Real Life Projects/Real Estate Analysis/GSMLS.py", line 950, in results_found
    check_all_results = WebDriverWait(driver_var, 30).until(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Python 2.0\pythonProject\venv\Real Estate Analysis\Lib\site-packages\selenium\webdriver\support\wait.py", line 95, in until
    raise TimeoutException(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message:

except ElementClickInterceptedException:
    element_not_found = True
    while element_not_found:
        try:
            GSMLS.set_county(county_id, driver_var)
            results1 = driver_var.page_source
            cities = GSMLS.find_cities(results1)
            cities_ids_list = cities.keys()
            element_not_found = False
        except ElementClickInterceptedException as ECIE:
            logger.exception(f'Retrying the selection of {counties[county_id]}\n{ECIE.msg}')
        # else:
        #     break
finally:


addy = addy.replace(r'\xa0', ' ').replace(r'Rd$', 'Road')\
            #     .replace(r'Ct$', 'Court').replace(r'St$', 'Street')\
            #     .replace(r'Ave$', 'Avenue').replace(r'Dr$', 'Drive')\
            #     .replace(r'Ln$', 'Lane').replace(r'Pl$', 'Place')\
            #     .replace(r'Ter$', 'Terrace').replace(r'Hwy$', 'Highway')\
            #     .replace(r'Pkwy$', 'Parkway').replace(r'Cir$', 'Circle')\
            #     .replace(r'.*', GSMLS.clean_addresses)