PRIORITIES:
1) NJTaxAssessment
- Create a class variable which will be a database of the cities and counties in NJ (DONE)
***Figure out how to properly add a package to sys.path and use it. Currently copied class from parent folder
***The url's arent https even though thats what I'm labeling them as. Figure this out. I think I need to add verifyssl=False
- Update city_database function
- Complete the code to stream Essex County property dbs (DONE)
    - The download_link isnt present sometimes and presents an error
    - Generate a different proxy then load webpage using city id (?town=0711), dont click the radio buttons anymore
    - Be sure to update the format_proxies function when done in the main file
    - May need to create a function loop to try different proxies until the download initiates
23) create decorator for nj_databases to create a time constraint for downloads (1 year)
2) GSMLS
- Complete the code to stream ALL property quarterly sales
    - Find the correct XPATH to select the target county. All XPATHs that I've tried thus far haven't works (DONE)
    - Make sure that WHILE loops has the correct exceptions to continue when needed (DONE)
    - Find the right action chains to insert the right file names (DONE)
    - Insert logger messages for what county is being run and when the downloads are completed (DONE)
    - Repeat code for MUL and LND (DONE)
- Refactor the clean_db function to adjust for RES, MUL and LND dbs
        - Add property_type as a function arg and add if statement blocks to allow the use of RES, MUL or LND property types
        - See if there are common columns between all dbs and use if statement blocks to add columns if necessary
        - Make sub-functions which will do the actual cleaning. Clean_db will be the main function
- Run descriptive statistics for all cities: max, min, mean, median, mode, stddev and quartiles
- Create function which creates email campaigns for specific counties and cities based on analysis results (adjusted every qtr)
- *** Create function to store all qtrly results in SQL after cleaning the data
- *** Create a script that is solely run to download the quarterly sales results for RES, MUL, and LND properties
- *** Create a script that is solely run to clean and transform the data to be stored in SQL databases
3) Complete lat_long function in GSMLS
    ****** Maybe shift to the GSMLS to use inside DealAnalyzer modules.
    Only run function when analyzing distance instead of running the risk of getting banded for webscrapping
    ***The new db should be immediately put back into SQL not another csv/xslx
    - The function will take the file as an arg and convert into Pandas db
    - Add Request module exceptions to the function
    - add logic for if county and or city vars arent None. Could be str or list types
    - Be sure to throttle the program by 1 sec after every request (DONE)
        - Build in a function to detect 400 and 500 level responses and adjust after
            - Use a While loop to continue running that address if 400 or 500 level responses are given
    - Delete all of the Selenium code and replace with Request and BS4 module syntax (DONE)
    - Track the 'importance' key of the JSON file. May depict the accuracy of the location (DONE)


4) Complete MachineLearning script
5) Start the DealAnalysis script
- Continually check if MLS deals are still available. Notice status changes
- Composite class (will use NJTaxAssessment, Foreclosures, GSMLS and MachineLearning
6) Complete HomeDepot Scrapper and Analysis
7) Complete Foreclosures script
8) NJ Planning Board Scraper
- Can I set up a REST API to check when each board is updated to then scrape?

NJTaxAssessment
________________________________________________________________________________
17) Add logger messages to necessary parts of the NJTaxAssessment code
20) Stream the zip file instead of downloading to reduce the built-in latency
    - Use the Requests ans Session.Requests module to stream the files. (ie: Scraper class) (PARTIALLY DONE)
    - Update the stream_zipfile function args to download_param= None, payload= None (is this still necessary?)
        - do if statement blocks that are executed based on the arg provided to the function
    - Needs to be implemented for the Essex County function (STREAMING EACH FILE CURRENTLY CANT BE DONE)
    *****There's a download limit on the website. Switch code to download all municipalities at one time
        - Build a Selenium latency to wait for download to finish (DONE)
        - Find a way to match the city with the downloaded file (NOT NECESSARY)
        **** Cookies wont let me download the file more than once. Download limit
            - Build in a timestamp method essex county scrape and timestamp= None arg into unzip and extract (DONE)
            If timestamp not None its automatically an Essex county file (DONE)
            If the delta between the timestamp and file download is less than X sec then name and move file, else continue
            - Can Python show metadata of a file? (DONE)
***21) Refactor city_database to open the "All Municipalities" xlsx for ESSEX county cities which dont have dbs
    - HOLD OFF ON THIS AS LAST RESORT
    - This code could present future errors for counties which have duplicate city spellings. Fix this
    - This file will only be used for cities which dont have DBs
5) Continue working on the long_lat function
    - Change the filename variable syntax so the files can be found
    - Create a db cleaning function to use inside lat_long
    - Change the sheet name during the db save to overwrite the first sheet

7)Foreclosure
____________________________________________________________________________________________________
    *** I want to store this as a SQL DB. This script will automatically check the site every week to update the status of the properties in the
    db. After X amount of time after the sale of the property, the SQL DB will delete that entry. And add new ones if they already dont exist
16) Alter the NJTaxAssessment class for the nj_databases to find the db for one county and one city as well
    - Create an arg entry for 'county' and 'city' in nj_databases
    - Create an arg entry for 'county' and 'city' in all_county_scrape
    - Create an arg entry for 'city' in essex_county_scrape
    ****Allow for str or list objects in these functions and alter the logic based on the object
    - Add 'if county is None, elif county is not None and city is None, elif county is not None and city is not None' in
        - all_county_scrape
        - nj_databases
    - Add 'if city is None, elif city is not None
18) Allow code to check what was downloaded already and start at new point
8) Continue working on the auction_locations function
    - Save this as a class variable

GSMLS class
________________________________________________________________________________________________________________________
    - Break quarterly_sales_res down into smaller/modular functions
    - Create a function which finds the recently downloaded file and move it to a specific folder, Use NJTaxAssessment function as a template
    - For quarterly sales_res
        Create function for:
        Create a function that asks the user which counties and cities they want to download for to
        account for cities and counties values as NONE
        - no county name(s) or city(s) provided (DONE)
        - one county name no city name
        - list of county names no city names
        - list of county names and list of names
    - Stream the xlsx file instead of downloading to reduce the built-in latency
        - Use the Requests an Session.Requests module to stream the files. (ie: Scraper class)
        - On the final download page, use the Elements and Network tabs to fill out the payload to stream the file

_______________________________________________________________________________________________________________________
Unassigned
3) Continue working on the property_tax_legend function
    - Create an excel sheet which will hold all the data
    - Use Regex to read the values of the cell and produce the values for the new column
9) Continue working on the haversine function
10) This is a program which will require the use of an SQL database
    Create a method which will transfer all of this data to PostgreSQL
11) Create a function which accepts the county and city as args, finds the latest downloaded zip (DONE)
    extracts the file and saves it as the city name in the county directory (DONE)
    11a) This should be a threaded operation. Create an empty list at the top of nj_database to store threaded operations (DONE)
14) Update waiting function
15) Update run_main decorator

Use when you want to implement threading
ALL COUNTYS
# download_link1 = driver_var.find_element(By.XPATH, "/html/body/form/b[2]/big/a")
# download_link1.click()  # Step 5: Download the zip file
# threadobj = threading.Thread(target=NJTaxAssessment.unzip_and_extract,
#                              args=[counties[key], cities[k], download_link.split('/')[2]])  # Step 6: Unzip and save file
# started_threads.append(threadobj)
# threadobj.start()

ESSEX COUNTY
# threadobj = threading.Thread(target=NJTaxAssessment.unzip_and_extract,
#                              args=['ESSEX', cities[k]])  # Step 6: Unzip and save file
# started_threads.append(threadobj)
# threadobj.start()

except ElementNotVisibleException as ENV:  # Make more specific exception handling blocks later
    logger.exception(f'{ENV}')

except ElementNotSelectableException as ENS:
    logger.exception(f'{ENS}')

except NoSuchElementException as NSEE:
    logger.exception(f'{NSEE}')

except WebDriverException as WDE:
    logger.exception(f'{traceback.format_tb(WDE.__traceback__)}')
    GSMLS.sign_out(driver_var)

else:

label[title='10 - Atlantic']