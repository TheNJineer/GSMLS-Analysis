PRIORITIES:
A)*** Use Apache Kafka, Apache Spark and Apache Airflow/NiFi to create a data pipeline for this system
        - Apache Kafka can help me send sales data in batches to be processed in real time instead
        of waiting for all the data to finish downloading to the process
        - Apache Airflow/NiFi will help with the workflow/data flow management of the complex system
    - Create Kafka topics called "Sold RES", "Sold MUL", "Sold LND", and "Pictures"
    - The GSMLS class will house all of the necessary functions to complete the pipeline
    - The first portion of the system will download data on a daily basis. Will be programmed using Apache Airflow and Python
        - Download the sales data and the associated pictures
        - Immediately send pictures to Kafka to be stored in Cassandra or MongoDB
    - Convert xls files to xlsx using the batch_conversion_macro.py to clean and store in JSON format
    - Use the GSMLS.clean_db_decorator as a template to understand what msgs need to be sent to Kafka so downstream trasnformation
    can be seamless
        - Create a metadata_json to hold main file contents and data for later transformations
        {"metadata":
            {"city_name":"", "city_name2":"", "county":"", "property_type":"", "mls_type":"", "qtr":"", "year":"", "median_sales_price":""},
         "main_data": json
            }
    - Use pandas to convert xlsx content to JSON (json = df.to_json())
    - Produce JSON data to Kafka
    - Consume the the JSON data from Kafka using Apache Spark and Apache Airflow/NiFi and complete the rest of the data transformation and enrichment
    - Store data in PostgreSQL for data exploration

1) NJTaxAssessment
***Figure out how to properly add a package to sys.path and use it. Currently copied class from parent folder
***The url's arent https even though thats what I'm labeling them as. Figure this out. I think I need to add verifyssl=False
- Update city_database function
- Complete the code to stream Essex County property dbs (DONE)
    - The download_link isnt present sometimes and presents an error
    - Generate a different proxy then load webpage using city id (?town=0711), dont click the radio buttons anymore
    - Be sure to update the format_proxies function when done in the main file
    - May need to create a function loop to try different proxies until the download initiates
    - Use SeleniumWire to intercept some of the driver requests to read/change the payloads to get the dbs I need
- Create decorator for nj_databases to create a time constraint for downloads (1 year)
- Make sure all Essex County tax db's 'Property Location' columns are converted to string types and addresses all converted to uppercase to work with program
- Make sure the address regex patterns can recognize the S,W,E,N directions


2) GSMLS
***CHECKPOINT: sq_ft_search experiences random failures when the sidebar_buttons cant be found. Figure this out
selenium.common.exceptions.WebDriverException: Message: unknown error: failed to close window in 20 seconds
  (Session info: MicrosoftEdge=121.0.2277.128)

- clean_db_decorator()
    - Create a seperate function to parse the county, city_name, property_type, mls_type, qtr, year

- Find a way to clean up the code for find_sq_ft, sq_ft_search and sq_ft_search_keyerror
    convert_lot_size
  *** Organize STF folder. Remove old Excel files
_ ***Create a function called old_sold_data() that utilizes the quarterly_sales functions to download all of the listings from
    1990-2022 for RES, MUL and LND
    - I'll have to update the page_criteria function to accept another arg so I can switch between "S" and "SD" (DONE)
    - I'll have to find a way to update the quarterly_sales decorator to cycle through the old years
        - old_sold_data() doesnt need to be created. Retrofit all quarterly_sales() functions to have a status_var and year_var
        - The status_var would allow the functions switch between any property status necessary
        - For the year_var, the default value is None. If none, the decorator will use the current year time_periods dict
        - If year_var is not None, use the old_sold_time_periods dict
        - Figure out what data type will be accepted for the year_var and how to cycle through the years
        - Create an old_sold run log to house the download status of each year and qtr and shelve it(model off of GSMLS Run Dictionary)

- FileNotFoundError is raised when loading the tax_db due to certain city names not being spelled correctly (ie: Andover vs Andover Township & Borough) (DONE)
    - Incorporate FileNotFoundError exception and modify names until file found (DONE)
    - FileNotFoundError: [WinError 3] The system cannot find the path specified: 'F:\\Real Estate Investing\\JQH Holding Company LLC\\Property Data\\SUSSEX\\ANDOVER' (DONE)
    - city_list = os.listdir(target_path) (DONE)
    - Create function called tax_db_notfound(city_name2) (DONE)
    - Ocean County doesn't have tax_dbs. For cities located in these counties, set tax_db = None (DONE)
    - Have sq_ft_finder set all NA's in the mls_db to 0 and cast column datatype to int64 (DONE)

- Extend the pattern search for convert_lot_size()
    - Add a redundant .str.rstrip('ABCDEFGabcdef') on thr target1 in fix_lotsize() before trying to convert the type to float
    - Land acres pattern needs to inlcude IRR, and all other abrv (DONE)
    - Make sure the 'AC' pattern works even when 'AC' isnt there (DONE)
    - Completely redo the convert_lot_size function (DONE)
        - initial wrapper function accepts all string values
        - Then, if string value meets a certain regex pattern, it initiate the function (DONE)
        - Currently, the column is going through 2 conversion functions and giving bad results (DONE)
        - Also add to acres pattern: \.\d{1,4}\sACRE(S)?, \.\d{1,4}\sAcre(s)? (DONE)
        - Also add to lxw pattern: \d{1,5})\sX\s(\d{1,5} AVG, \d{1,3}\.\d{1,5})\sX\s(\d{1,5} (DONE)
        - Theres a chance that both the acres and lot lxw is added. Create a seperate regex pattern for that (DONE)
        - The current patterns returns whatever pattern is matches first. This creates a problem for results with AC and ACRES. How do I fix this? (DONE)
        ValueError: could not convert string to float: '175111.2RES': Error while type casting for column 'LOTSIZE (SQFT)' (DONE)
        - Lot sizes with just decimals numbers will trigger most of the patterns. How do I stop that? (DONE)
        - The patterns 'ACRE', 'ACS', 'Acres' doesnt show up in the acres_pattern. Add this
            - Turn the acres pattern into an re.compile object to include the re.ignorecase flag
        - Create a pattern for lot size when two or more pattern type values are found in the cells

- Cast the respective columns which use .str methods to strings in the clean_and_transfer_data functions
- Properly accept the property_archive() traceback and use the correct except block (DONE)
- Make sure the address regex patterns can recognize the S,W,E,N directions
- Integrate find_sq_ft for MUL properties (DONE)
    - Integrate the property type into sq_ft_search and sq_ft_keyerror (NOT NECESSARY)
    - Create two modular functions which should be housed inside sq_ft_search that will be activated depending on the property type (NOT NECESSARY)
    - The MUL function should be exactly identical to the RES function. Just replace 'SQFTAPPROX' with 'SQFTBLDG' (NOT NECESSARY)
    - Change the 'SQFTBLDG' column to 'SQFTAPPROX' during the cleaning so I dont have to unnecessarily create new functions (DONE)
- Create a function to house the string replacement methods on the address column
- Add logic that creates a new window when doing an rpr_search() (DONE)
    - Add logic to close the rpr_sq_ft window and clear the text from the rpr search box when search is complete then switch window (DONE)
- Work on potential_farm_area() (DONE)
    - How can I do this process easier?
- Separate property_archive function into smaller functions:
    - address_list_scrape() (DONE)
        - I need to log the address that I find as well to see the address format
- Refactor the property_archive() function to produce the property listing history (DONE)
- Add a function which looks into RPR if none of the property archive addresses work (DONE)
    - Make sure rpr works properly when an address isnt found
        - rpr_search_address(): Switch back to GSMLS tab if no address if found (Dont switch if theres no new tab open) (DONE)
        - I also need to clear the results of the search page too regardless of if theres anything found (DONE)
    - Make sure rpr_property_facts works as intended
- Figure out how to automate the operation of the macro immediately after download and dispose of the old files
    - Make sure the clean_db decorator skips the Batch File Conversion xlsx
- Create a new directory called 'GSMLS' in the Selenium Temp Folder to put downloads in. Switch to this directory in the main function
- Consolidate the 'MUL' and 'LND' quarterly_sales function into one. Accept property_type as an arg to use as a switch case
    - Modify the decorator to insert the property type as an arg
- Create a try-except block in the main function which can be used to restart the program recursively
- Refactor the main() function to not login to GSMLS if theres not data to download
- Use Funct.tools to get the proper names for the function when going through the decorators
- A selenium TimeoutError can occur if a page element isnt found. How to I get around this to continue the program?
_ Refactor the run_main decorator to run on a quarterly basis
    - uses a shelve file to know which dates to download for
- Fix the clean_and_transform function:
    - Round the BATHSTOTAL column to one dec place
    - SPLP should be rounded to 3 decimal places
- *** Create function to store all qtrly results in SQL after cleaning the data (DONE)
    - Update the rename_pandas_columns function to work for RES, MUL, and LND dbs. Also get the correct list of column names
    - Use the clean_db() and new pandas2sql() (DONE)
- Figure out how to properly calculate the Z-Score for the LND and MUL data
    - I may have to wait until the LND and MUL database is created then pull the mean prices from there
- Track rental prices as well

3) Complete lat_long function in GSMLS
    ****** Maybe shift to the GSMLS to use inside DealAnalyzer modules. (DONE)
    Only run function when analyzing distance instead of running the risk of getting banded for webscrapping
    ***The lat_long results should be immediately put back into SQL as a table update
    - The function will take the file as an arg and convert into Pandas db
    - Add Request module exceptions to the function
    - add logic for if county and or city vars arent None. Could be str or list types
    - Be sure to throttle the program by 1 sec after every request (DONE)
        - Build in a function to detect 400 and 500 level responses and adjust after
            - Use a While loop to continue running that address if 400 or 500 level responses are given
    - Delete all of the Selenium code and replace with Request and BS4 module syntax (DONE)
    - Track the 'importance' key of the JSON file. May depict the accuracy of the location (DONE)
- Run descriptive statistics for all cities: max, min, mean, median, mode, stddev and quartiles
- Create function which creates email campaigns for specific counties and cities based on analysis results (adjusted every qtr)
- *** Create a script that is solely run to download the quarterly sales results for RES, MUL, and LND properties
- *** Create a script that is solely run to clean and transform the data to be stored in SQL databases

4) Complete MachineLearning script
5) Start the DealAnalysis script
- Continually check if MLS deals are still available. Notice status changes
- Composite class (will use NJTaxAssessment, Foreclosures, GSMLS and MachineLearning
6) Complete HomeDepot Scrapper and Analysis
7) Complete Foreclosures script
8) NJ Planning Board Scraper
- Can I set up a REST API to check when each board is updated to then scrape?

NJTaxAssessment
________________________________________________________________________________
17) Add logger messages to necessary parts of the NJTaxAssessment code
20) Stream the zip file instead of downloading to reduce the built-in latency
    - Use the Requests ans Session.Requests module to stream the files. (ie: Scraper class) (PARTIALLY DONE)
    - Update the stream_zipfile function args to download_param= None, payload= None (is this still necessary?)
        - do if statement blocks that are executed based on the arg provided to the function
    - Needs to be implemented for the Essex County function (STREAMING EACH FILE CURRENTLY CANT BE DONE)
    *****There's a download limit on the website. Switch code to download all municipalities at one time
        - Build a Selenium latency to wait for download to finish (DONE)
        - Find a way to match the city with the downloaded file (NOT NECESSARY)
        **** Cookies wont let me download the file more than once. Download limit
            - Build in a timestamp method essex county scrape and timestamp= None arg into unzip and extract (DONE)
            If timestamp not None its automatically an Essex county file (DONE)
            If the delta between the timestamp and file download is less than X sec then name and move file, else continue
            - Can Python show metadata of a file? (DONE)
***21) Refactor city_database to open the "All Municipalities" xlsx for ESSEX county cities which dont have dbs
    - HOLD OFF ON THIS AS LAST RESORT
    - This code could present future errors for counties which have duplicate city spellings. Fix this
    - This file will only be used for cities which dont have DBs
5) Continue working on the long_lat function
    - Change the filename variable syntax so the files can be found
    - Create a db cleaning function to use inside lat_long
    - Change the sheet name during the db save to overwrite the first sheet

7)Foreclosure
____________________________________________________________________________________________________
    *** I want to store this as a SQL DB. This script will automatically check the site every week to update the status of the properties in the
    db. After X amount of time after the sale of the property, the SQL DB will delete that entry. And add new ones if they already dont exist
16) Alter the NJTaxAssessment class for the nj_databases to find the db for one county and one city as well
    - Create an arg entry for 'county' and 'city' in nj_databases
    - Create an arg entry for 'county' and 'city' in all_county_scrape
    - Create an arg entry for 'city' in essex_county_scrape
    ****Allow for str or list objects in these functions and alter the logic based on the object
    - Add 'if county is None, elif county is not None and city is None, elif county is not None and city is not None' in
        - all_county_scrape
        - nj_databases
    - Add 'if city is None, elif city is not None
18) Allow code to check what was downloaded already and start at new point
8) Continue working on the auction_locations function
    - Save this as a class variable

GSMLS class
________________________________________________________________________________________________________________________
    - Break quarterly_sales_res down into smaller/modular functions
    - Create a function which finds the recently downloaded file and move it to a specific folder, Use NJTaxAssessment function as a template
    - For quarterly sales_res
        Create function for:
        Create a function that asks the user which counties and cities they want to download for to
        account for cities and counties values as NONE
        - no county name(s) or city(s) provided (DONE)
        - one county name no city name
        - list of county names no city names
        - list of county names and list of names
    - Stream the xlsx file instead of downloading to reduce the built-in latency
        - Use the Requests an Session.Requests module to stream the files. (ie: Scraper class)
        - On the final download page, use the Elements and Network tabs to fill out the payload to stream the file

_______________________________________________________________________________________________________________________
Unassigned
3) Continue working on the property_tax_legend function
    - Create an excel sheet which will hold all the data
    - Use Regex to read the values of the cell and produce the values for the new column
9) Continue working on the haversine function
10) This is a program which will require the use of an SQL database
    Create a method which will transfer all of this data to PostgreSQL
11) Create a function which accepts the county and city as args, finds the latest downloaded zip (DONE)
    extracts the file and saves it as the city name in the county directory (DONE)
    11a) This should be a threaded operation. Create an empty list at the top of nj_database to store threaded operations (DONE)
14) Update waiting function
15) Update run_main decorator

Use when you want to implement threading
ALL COUNTYS
# download_link1 = driver_var.find_element(By.XPATH, "/html/body/form/b[2]/big/a")
# download_link1.click()  # Step 5: Download the zip file
# threadobj = threading.Thread(target=NJTaxAssessment.unzip_and_extract,
#                              args=[counties[key], cities[k], download_link.split('/')[2]])  # Step 6: Unzip and save file
# started_threads.append(threadobj)
# threadobj.start()

ESSEX COUNTY
# threadobj = threading.Thread(target=NJTaxAssessment.unzip_and_extract,
#                              args=['ESSEX', cities[k]])  # Step 6: Unzip and save file
# started_threads.append(threadobj)
# threadobj.start()

except ElementNotVisibleException as ENV:  # Make more specific exception handling blocks later
    logger.exception(f'{ENV}')

except ElementNotSelectableException as ENS:
    logger.exception(f'{ENS}')

except NoSuchElementException as NSEE:
    logger.exception(f'{NSEE}')

except WebDriverException as WDE:
    logger.exception(f'{traceback.format_tb(WDE.__traceback__)}')
    GSMLS.sign_out(driver_var)

else:

label[title='10 - Atlantic']

Traceback (most recent call last):
  File "F:\Python 2.0\PyCharm Community Edition 2022.2.1\plugins\python-ce\helpers\pydev\pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Python 2.0\PyCharm Community Edition 2022.2.1\plugins\python-ce\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "F:/Python 2.0/Projects/Real Life Projects/Real Estate Analysis/GSMLS.py", line 1117, in <module>
    obj.main()
  File "F:/Python 2.0/Projects/Real Life Projects/Real Estate Analysis/GSMLS.py", line 1109, in main
    GSMLS.quarterly_sales_mul(driver)
  File "F:/Python 2.0/Projects/Real Life Projects/Real Estate Analysis/GSMLS.py", line 69, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:/Python 2.0/Projects/Real Life Projects/Real Estate Analysis/GSMLS.py", line 714, in quarterly_sales_mul
    GSMLS.results_found(driver_var, cities[city_id], qtr, 'MUL')
  File "F:/Python 2.0/Projects/Real Life Projects/Real Estate Analysis/GSMLS.py", line 950, in results_found
    check_all_results = WebDriverWait(driver_var, 30).until(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Python 2.0\pythonProject\venv\Real Estate Analysis\Lib\site-packages\selenium\webdriver\support\wait.py", line 95, in until
    raise TimeoutException(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message:

except ElementClickInterceptedException:
    element_not_found = True
    while element_not_found:
        try:
            GSMLS.set_county(county_id, driver_var)
            results1 = driver_var.page_source
            cities = GSMLS.find_cities(results1)
            cities_ids_list = cities.keys()
            element_not_found = False
        except ElementClickInterceptedException as ECIE:
            logger.exception(f'Retrying the selection of {counties[county_id]}\n{ECIE.msg}')
        # else:
        #     break
finally:


addy = addy.replace(r'\xa0', ' ').replace(r'Rd$', 'Road')\
            #     .replace(r'Ct$', 'Court').replace(r'St$', 'Street')\
            #     .replace(r'Ave$', 'Avenue').replace(r'Dr$', 'Drive')\
            #     .replace(r'Ln$', 'Lane').replace(r'Pl$', 'Place')\
            #     .replace(r'Ter$', 'Terrace').replace(r'Hwy$', 'Highway')\
            #     .replace(r'Pkwy$', 'Parkway').replace(r'Cir$', 'Circle')\
            #     .replace(r'.*', GSMLS.clean_addresses)


 acres_pattern = r'(\.\d{1,6}(\sAC)?|\.\d{1,6}(\sAC.)?|\d{1,4}\.\d{1,6}(\sAC)?|\d{1,4}\.\d{1,6}(\sAC.)?|' \
                        r'\d{0,4}\.\d{1,4}\sACRE(S)?|\d{0,4}\.\d{1,4}\sAcre(s)?)'
                        (\d{1,4})?\.\d{1,6}(\s)?ac(\.)?(re(s)?)?
        by_pattern = r'(\d{1,5})X\s(\d{1,5})|(\d{1,5})X(\d{1,5})|(\d{1,5})\sX\s(\d{1,5})|(\d{1,5})\sX(\d{1,5}|' \
                     r'\d{1,5})\sX\s(\d{1,5}\sAVG|\d{1,3}\.\d{1,5})\sX\s(\d{1,5})'
        # db = db.astype({'LOTSIZE': 'string'})
        lotsize_sqft = db['LOTSIZE']

        if property_type == 'RES':
            db.insert(12, 'LOTSIZE (SQFT)',
                      lotsize_sqft.str.replace(acres_pattern, GSMLS.acres_to_sqft, regex=True)
                      .str.replace(by_pattern, GSMLS.length_and_width_to_sqft, regex=True).str.rstrip('.')
                      .str.replace(',', ''))

        elif property_type == 'MUL':
            db.insert(12, 'LOTSIZE (SQFT)',
                      lotsize_sqft.str.replace(acres_pattern, GSMLS.acres_to_sqft, regex=True)
                      .str.replace(by_pattern, GSMLS.length_and_width_to_sqft, regex=True).str.rstrip('.')
                      .str.replace(',', ''))

        elif property_type == 'LND':
            db.insert(12, 'LOTSIZE (SQFT)',
                      lotsize_sqft.str.replace(acres_pattern, GSMLS.acres_to_sqft, regex=True)
                      .str.replace(by_pattern, GSMLS.length_and_width_to_sqft, regex=True).str.rstrip('.')
                      .str.replace(',', ''))

        db = db.astype({'LOTSIZE (SQFT)': 'float64'})
        db = db.round({'LOTSIZE (SQFT)': 2})

        return db


 @staticmethod
    def length_and_width_to_sqft(search_string):
        if search_string.group(1) is not None:
            return str((float(search_string.group(1)) * float(search_string.group(2))))
        elif search_string.group(3) is not None:
            return str((float(search_string.group(3)) * float(search_string.group(4))))
        elif search_string.group(5) is not None:
            return str((float(search_string.group(5)) * float(search_string.group(6))))
        elif search_string.group(7) is not None:
            return str((float(search_string.group(7)) * float(search_string.group(8))))

KeyError: '17 E MAIN STREET'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:/Python 2.0/Projects/Real Life Projects/Real Estate Analysis/GSMLS.py", line 2427, in sq_ft_search
    return GSMLS.sq_ft_keyerror(mls_address, mls_db, tax_db, outer_address_list, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:/Python 2.0/Projects/Real Life Projects/Real Estate Analysis/GSMLS.py", line 2254, in sq_ft_keyerror
    address_list = GSMLS.property_archive(mls_number, mls_address, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:/Python 2.0/Projects/Real Life Projects/Real Estate Analysis/GSMLS.py", line 1445, in property_archive
    new_window, sidebar_buttons = GSMLS.open_property_listing(driver, open_window_list, contact_num)
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:/Python 2.0/Projects/Real Life Projects/Real Estate Analysis/GSMLS.py", line 1334, in open_property_listing
    sidebar_buttons = sidebar_table.find_all('div', {"class": "sidebar-button select"})
                      ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'find_all'