***The main focus is to have GSMLS.py as the producer of data and nothing else
All transformations and data imputations will happen in another script
***However, until I have the hardware and resources, each year of dat will be produced them
consumed in a synchronous manner
***Add a local postgresql connection to excel

ETL Pipeline:
1a) GSMLS Produces data and pictures
1b) Bright MLS produces data and pictures
2a) BrightMLS and GSMLS pictures are downloaded to harddrive
2b) Batch clean the data as it comes in
- Turn stream into a SparkDB
- Clean the database
- Fix lot size
- clean addresses
3) clean, find and impute sq ft
4) Store cleaned data in PostgreSQL

GSMLS Workflow:
*** Have all the dates I want to scrape be input as a function arg
*** Maybe I have the decorator handling the county, cities and dates
1) Login in
- Remove welcome message box if necessary
2) Go to Quicksearch
- Set value to XLY which looks for all property types
3) Set the values for the property types I want
4) Depending on the date, set old sold, old expired and old withdrawn or sold, withdrawn, expired, available
5) Set the start and end dates
5) Scrape all counties and loop through each one
6) Loop through each municipality of each county to look for data
7) *Create a function which splits the dates up if too many results are found
8a) If no results found, continue
8b) If results found, return results
9) Scrape the images, property archive data (if available) and the latitude and longitude data from this page
10) Save the results in an xls file
11) Format all the results into a pandas database
12) Produce data to Kafka

PRIORITY LIST:
2) Create a run summary to be emailed when complete
    - Renew the Gmail API
    - Include rows produced, years/qtr scrapped and errors encountered
    - Turn Log_Parse.py into a function and put at the end of the obj.main()
    - Create an emailed summary for each loop of a property type has been scraped
    - Create one function that sends an email after these conditions are met:
          - Create an emailed summary for each loop of a property type has been scraped
          - Create a run summary to be emailed when complete
          - Create a one-hour heart beat saying the status/health of the producer, and server and the last scraped data
3) Put print statements in the function
    - Adjust the print statements; make them cleaner
    - Add tqdm bars to the consume data function
    - Add tqdm bars into each of the property cleaning main functions (accept the tdqm manager as a function arg)
4) Think amount using a context manager for the PostgreSQL connections
    - Doesnt matter, I believe there's an issue with trying to properly handle nested bars
5) Create a function which dynamically handles the errors and kills the program under specific circumstances
8) If there's no data returned in the consume_data function, return a string value that keeps the program moving
    - ValueError: No objects to concatenate
9) UserWarning: the 'timedelta' type is not supported, and will be written as integer values (ns frequency) to the database.
Create function which transforms this to the desired time
10) Instead of going by each muni for LND, scrape by county the full year in one pass
15) Add KeyboardIntercept as an excepted error for data to be saved
    - Figure out a way to have the KeyboardInterupt and AssertionError initiated and data still saved
    - KeyboardInts arent getting respected right now
20) check if tax data timedelta columns are in ns frequency
*** The LOT data is currently bigint but the data could potentially have letters in it. Should this be changed to text datatype? (TAX)
*** GSMLS Tax data is updated after every sale and replaces the previous records. Cant rely on the time_of_posession data
21) False positives for 'Fixer Upper' properties. Descriptions with 'molding' in it are being described as TLC because it's a partial match
    Fix this! Make full match!
22) Create a save point for after every county is scraped


Update Tasks:
1) Properly format the logger function and the tqdm bars
2) Make sure the PostgreSQL connection is closed if the AssertionError or NoBrokerAvailable errors are raised
3) Create a function using Regex to create a dictionary/histogram of the municipality subsection names. Track the min/max
    latitudes and longitudes as well as the subsection names
8) Use MongoDB to store the binary data of the images with it's metadata and labels
11) Process and transform data to apply labels to pictures then save to MongoDB
14) Change the "CONDITION" and "POTENTIAL INVESTMENT" column value to "Fixer Upper" and True if criteria is met
    - Use a combination of the difference between original list price & list price, SP/OLP%, loan_terms, days to close
16) I fcked that tax_properties shelve up. Data may be lost, 2000 TAX data will need to be redownloaded
18) Download and install Apache Airflow
19) *** THERE'S DATA MISSING!!! FIGURE OUT HOW TO ENSURE ALL DATA IS BEING RECEIVED!!!
20) TimeoutErrors occuring on the format_data_for_kafka and no_results() figure this out
22) Increase the brokers running and the replication factors
25) Create new columns:
    - AGE_OF_PROPERTY (after tax data enrichment)
    - Calculate years in possession before sale to help with labelling (Column name: Time off market) DONE
    - Create a function that imputes sqftapprox by querying all listings that match that tax id. If none exist, then impute using
    the NJ Tax Assessment DB
    - Get the NJ Bank Codes excel and turn into a database (in Apple Files)
    *** - Create function that uses NLTK Sentiment Analysis on the Listing Remarks column
    - Can I create a column that quantifies how many previous sales the property has
24) Give the Kafka_GSMLSConsumer the ability to mark a home as Newly Renovated as well as New Construction
    - New Construction: 'recently constructed|new construction|(?:brand\s)new construction|recently renovated'
    - Renovated: 'completely re/-?built|renovated|fully renovated'
    - Create new regex patterns that are put in the fixer_upper function
    - Will require new columns
25) Create a boolean column for MUL data that accounts for 5+ units
    - Create a separate function that says if x > 6, return True, else False
    - Add new column in PostgresSQL before doing this
23) Create a label for North, Central, and South Jersey
    - Will require a new column
26) Remove records from MongoDB which image arrays are empty
27) Add patterns
29) Create an instance variable that holds the window id numbers to easily switch back and forth to them
28) Handle a "too many results" instance in too_many_results():
    - split_search_dates handles this on a yearly level DONE
    - Create functions which can handle it on quarterly DONE
    - Create functions to handle it on a monthly level MANDORTY DONE NEXT!!!
    ***Update the name of the file and key in these functions so data isnt overriden
    in Kafka
29) Create NJ_TOWNCODE column
30) Create geomap account for API and finish function
31) Remove duplicate records with the same MLSNUM in MongoDB

//button[@id='listings'


*** I DO NOT HAVE TO SCRAPE ADDITIONAL ADDRESSES
- USE THE NJ TAX ASSESSMENT DATA TO FILL IN ANY INFORMATION GAPS
- USE A COMBINATION OF THE CITY NAME, BLOCK AND LOT NUMBER AND STREET ADDRESS TO FILL IN
    - TOTAL ASSESSMENT, TAX RATE, TOTAL TAX, LOT SIZE, BLG DESCRIPTION, TAX ZONE, SQFT

Keeping functions:
- quarterly_sales_res
- quicksearch
- page_criteria
- res_property_styles
- find_counties
- find_cities
- set_dates
- cities_download_manager
- download_manager
- set_county
- set_city
- show_results
- sign_out
- no_results
- results_found
- format_data_for_kafka
- get_us_pw
- login
- scrape_image_links
- publish_data_2kafka
- first_media_link
- address_list_scrape
- address_table_results
- property_archive
- clean_address
- kill_logger
- open_property_listing
- search_listing
- sendfile2trash

Undecided functions:
- available_inventory (DONE)
- lat_long (DONE)

Deleting functions:
- quarterly_sales_mul (DONE)
- quarterly_sales_lnd (DONE)
- check_run_log (DONE)
- convert_xls_2_xlsx (DONE)
- create_lnd_sales_table (DONE)
- create_mul_sales_table (DONE)
- create_res_sales_table (DONE)
- create_sql_table (DONE)
- email_campaign (DONE)
- open_browser_windows (DONE)
- open_run_log (DONE)
- pandas2sql (DONE)
- sql_table_check (DONE)
- under_contract (DONE)

Move to new script:
- acres_to_sqft (DONE)
- sq_ft_keyerror (DONE)
- sq_ft_search (DONE)
- address_list_scrape
- address_table_results
- property_archive
- clean_and_transform_data_lnd/mul/res (DONE)
- clean_db (DONE)
- comps (DONE)
- connect2postgresql() (DONE)
- convert_lot_size (DONE)
- find_sq_ft (DONE)
- fix_lotsize (DONE)
- length_and_width_to_sqft (DONE)
- paired_sales_analysis (DONE)
- quarterly_appr_depr (DONE)
- rpr (DONE)
- rpr_property_facts (DONE)
- rpr_search_address (DONE)
- rpr_sq_ft (DONE)
- sq_ft_pattern_clean (DONE)
- tax_db_notfound (DONE)
- total_units (DONE)

______________________________________________________________________________________________________________________
______________________________________________________________________________________________________________________

    @staticmethod
    def first_media_link(target_str):

        if '\n' or '\t' in target_str:
            target_str = [i for i in target_str if i not in ['\n', '\t']]
            if target_str[-1].isalpha():
                target_str = ' '.join([''.join(target_str[:-1]), target_str[-1]])
            else:
                target_str = ''.join(target_str)

        return target_str

    @staticmethod
    def quarterly_sales(original_function):
        def wrapper(*args, **kwargs):

            logger = kwargs['logger']
            f_handler = kwargs['f_handler']
            c_handler = kwargs['c_handler']

            for year in range(1990, datetime.now().year + 1):

                time_periods = {
                    'Q1': [f'01/01/{year}', f'03/31/{year}'],
                    'Q2': [f'04/01/{year}', f'06/30/{year}'],
                    'Q3': [f'07/01/{year}', f'09/30/{year}'],
                    'Q4': [f'10/01/{year}', f'12/31/{year}']
                }

                for qtr, date_range in time_periods.items():
                    kwargs['Qtr'] = qtr
                    kwargs['Dates'] = date_range
                    if datetime.today() >= datetime.strptime(date_range[1], '%m/%d/%Y'):

                        # if run_log[property_type][qtr] == 'D.N.A':
                            # D.N.A means 'Data Not Available'
                            # run_log = original_function(*args, **kwargs)
                        original_function(*args, **kwargs)

                        # elif run_log[property_type][qtr] == 'IN PROGRESS':
                        #     # run modified_quarterly_download
                        #     previous_dir = os.getcwd()
                        #     path = 'C:\\Users\\Omar\\Desktop\\Selenium Temp Folder'
                        #     os.chdir(path)
                        #     latest_file = sorted(os.listdir(path), key=lambda x: os.path.getctime(x))[-1]
                        #     db = pd.read_excel(latest_file)
                        #     os.chdir(previous_dir)
                        #     kwargs['city_name'] = latest_file.split('Q')[0].strip()
                        #     kwargs['county_name'] = db.loc[0, 'COUNTY'].rstrip('*')
                        #     run_log = original_function(*args, **kwargs)
                        #
                        # elif run_log[property_type][qtr] == 'DOWNLOADED':
                        #     logger.info(f'The {property_type} data has already been downloaded for {qtr}')
                        #     pass

                    else:
                        # May need to put a logger msg here
                        # May need to break the code here. No sense of continuing the loop if all subsequent data isnt
                        # available
                        continue

            logger.removeHandler(f_handler)
            logger.removeHandler(c_handler)
            logging.shutdown()

        return wrapper

       @staticmethod
    def download_manager(city_name, city_id, county_name, qtr, driver_var, **kwargs):

        logger = kwargs['logger']
        file_name = GSMLS.results_found(driver_var, city_name, qtr, county_name)
        time.sleep(1.5)  # Built-in latency to allow for file to xls file to download
        GSMLS.format_data_for_kafka(driver_var, driver_var.page_results, file_name, **kwargs)

        close_form = WebDriverWait(driver_var, 60).until(
            EC.presence_of_element_located((By.XPATH, "//*[@id='sub-navigation-container']/div/nav[1]/a[15]")))
        close_form.click()
        GSMLS.set_city(city_id, driver_var)
        logger.info(f'{file_name} has been downloaded')

    @staticmethod
    def results_found(driver_var, city_var, qtr_var, county_name):

        check_all_results = WebDriverWait(driver_var, 30).until(
            EC.presence_of_element_located((By.ID, 'checkall')))
        check_all_results.click()
        download_results = driver_var.find_element(By.XPATH, '//*[@id="sub-navigation-container"]/div/nav[1]/a[12]')
        download_results.click()
        download_button = WebDriverWait(driver_var, 5).until(
            EC.presence_of_element_located((By.XPATH, "//a[normalize-space()='Download']")))
        excel_file_input = driver_var.find_element(By.ID, 'downloadfiletype3')
        excel_file_input.click()
        filename_input = driver_var.find_element(By.ID, 'filename')
        filename_input.click()
        filename = city_var + ' ' + county_name + ' ' + qtr_var + str(datetime.today().year) + ' ' + ' Sales GSMLS'
        AC(driver_var).key_down(Keys.CONTROL).send_keys('A').key_up(Keys.CONTROL).send_keys(filename).perform()
        time.sleep(0.5)
        download_button.click()
        close_page = driver_var.find_element(By.XPATH, "//*[@id='sub-navigation-container']/div/nav[1]/a[2]")
        close_page.click()

        return filename

    @staticmethod
    def quarterly_sales_res(driver_var, status_var, county_name=None, city_name=None, **kwargs):
        """
        Method that downloads all the sold homes for each city after each quarter.
        This will help me build a database for all previously
        sold homes to run analysis. Save the name of the file with the city name, the county, quarter, year.
        This initial dataframe will be dirty and have unnecessary information.
        Will be saved to Selenium Temp folder to be cleaned for future use by other methods.

        Will cause ElementClickIntercepted errors if not run on full screen

        :param driver_var:
        :param status_var
        :param county_name:
        :param city_name:
        :param kwargs:
        :return:
        """

        logger = kwargs['logger']
        f_handler = kwargs['f_handler']
        c_handler = kwargs['c_handler']
        qtr = kwargs['Qtr']
        date_range = kwargs['Dates']
        property_type = 'RES'
        kwargs['data-producer'] = KafkaProducer(bootstrap_servers='localhost:9092',
                                                value_serializer=lambda v: json.dumps(v).encode('utf-8'),
                                                key_serializer=lambda k: bytes(k, 'utf-8'))
        kwargs['image-producer'] = KafkaProducer(bootstrap_servers='localhost:9092',
                                                value_serializer=lambda v: json.dumps(v).encode('utf-8'),)

        page_check = WebDriverWait(driver_var, 10).until(
            EC.presence_of_element_located((By.CLASS_NAME, 'required')))

        if page_check:
            results = driver_var.page_source
            counties = GSMLS.find_counties(results)  # Step 3: Find all the counties available
            logger.info(f'Results for {qtr} ({date_range[0]} - {date_range[1]}) will now be extracted.')

            counties_ids_list = counties.keys()

            if (county_name and city_name) is None:

                for county_id in counties_ids_list:
                    if counties[county_id] == 'Other':
                        continue
                    else:
                        # Step 5: Search for all available municipalities in the target county
                        kwargs['county'] = counties[county_id] + ' County'
                        cities = GSMLS.cities_download_manager(counties, county_id, driver_var, logger)
                        cities_ids_list = cities.keys()

                        for city_id in cities_ids_list:
                            # Step 6: Download sales data from all municipalities which has data
                            # If no data is available, continue the program
                            GSMLS.download_manager(cities, city_id, property_type, qtr, driver_var, **kwargs)

                        logger.info(
                            f'Sales data for municipalities located in {counties[county_id]} County is now complete')
                        GSMLS.set_county(county_id, driver_var)

            elif (county_name and city_name) is not None:
                # Step 3a: There are instances where the program can be terminated due to selenium exceptions
                # One particular exception is the TimeoutException which occurs when an element cant be found
                # This code block allows the program to continue where it left off
                switch_case = 'YES'

                # Modify the county list to start from the county where the program was terminated
                county_index = list(counties.values()).index(county_name)
                counties_ids_list = list(counties.keys())[county_index:]

                for county_id in counties_ids_list:
                    if counties[county_id] == 'Other':
                        continue
                    else:

                        cities = GSMLS.cities_download_manager(counties, county_id, driver_var, logger)

                        if switch_case == 'YES':
                            try:
                                # Step 6a:
                                # Modify the city list to start from the city where the program was terminated
                                city_index = list(cities.values()).index(city_name)
                                cities_ids_list = list(cities.keys())[city_index + 1:]
                            except ValueError:
                                cities_ids_list = cities.keys()
                        else:
                            cities_ids_list = cities.keys()

                        for city_id in cities_ids_list:
                            GSMLS.download_manager(cities, city_id, property_type, qtr, driver_var, **kwargs)

                        logger.info(
                            f'Sales data for municipalities located in {counties[county_id]} County is now complete')
                        GSMLS.set_county(county_id, driver_var)
                        switch_case = 'NO'

        logger.removeHandler(f_handler)
        logger.removeHandler(c_handler)
        logging.shutdown()
    @staticmethod
    def res_property_styles(driver_var, page_source):
        """

        :param driver_var:
        :param page_source:
        :return:
        """
        prop_style_pattern = re.compile(r'title="(.*)"')
        soup = BeautifulSoup(page_source, 'html.parser')
        target = soup.find_all('div', {"class": "selection-item"})
        property_style_dict = {}

        for idx, i in enumerate(target[22:]):  # Target[22] is the first instance of property types
            target_contents = str(i)
            prop_style_search = prop_style_pattern.search(target_contents)
            property_style_dict[idx + 1] = prop_style_search.group(1)

        for k in property_style_dict.keys():
            if k in [1, 18, 20, 25, 26, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42]:
                continue
            else:
                selection = driver_var.find_element(By.ID, "selectedStyle" + str(k))
                selection.click()
        @staticmethod
    def acres_to_sqft(search_string):
        return str(round(float(search_string.group(1).rstrip(' ACRESacres.')) * 43560, 2))

    @staticmethod
    def clean_and_transform_data_lnd(pandas_db, mls, qtr):
        """
        Cleaning that needs to be done
        1. Filter for columns that I want displayed
        2. Remove the asterics attached to the following columns:
            BLOCKID, COUNTY, LOTSIZE, LOTID, STREETNAME
        3. Remove the *(NNNN*) from the town name
        4. Make LISTDATE, PENDINGDATE, CLOSEDDATE columns date type
        5. If no POOL, fillna with 'N' and POOLDESC with 'N'
        6. Create ADDRESS column by combining the 'STREETNUMDISPLAY' and 'STREETNAME' columns
        7. Create 'LATITUDE' AND 'LONGITUTDE' columns and fill with 'N/A'. Move columns right before ADDRESS column
        8. Add a column named "UC-Days" which calculates the total days between going under contract and closing
            # Can be vectorized by doing db['UC-Days'] = db['Closing Date'] - db['Under Contract']
        9. Convert all the values in the LOTSIZE column to sqft. Use Pandas str methods
        :param pandas_db:
        :param mls
        :param qtr
        :return:
        """

        pandas_db = pandas_db.astype({'STREETNUMDISPLAY': 'string', 'STREETNAME': 'string',
                                      'ORIGLISTPRICE': 'int64', 'LISTPRICE': 'int64', 'SALESPRICE': 'int64',
                                      'LOTSIZE': 'string', 'MLSNUM': 'string',
                                      'BLOCKID': 'string', 'LOTID': 'string', 'TAXID': 'string'})
        pandas_db.round({'SPLP': 3})

        # List item 2
        pandas_db['MLS'] = mls
        pandas_db['VARIANCE NEEDED'] = 'N*'  # This is a temporary value which will be changed to either Y or N when the function is created
        pandas_db['QTR'] = qtr
        pandas_db['Z-SCORE'] = (pandas_db['SALESPRICE'] - pandas_db['SALESPRICE'].mean()) / pandas_db[
            'SALESPRICE'].std()
        pandas_db.insert(0, 'MLS', pandas_db.pop('MLS'))
        pandas_db.insert(1, 'QTR', pandas_db.pop('QTR'))
        pandas_db.insert(2, 'LATITUDE', 0)
        pandas_db.insert(3, 'LONGITUDE', 0)
        pandas_db.insert(4, 'BLOCKID', pandas_db.pop('BLOCKID').str.strip('*'))
        pandas_db.insert(5, 'LOTID', pandas_db.pop('LOTID').str.strip('*'))
        pandas_db.insert(6, 'STREETNAME', pandas_db.pop('STREETNAME').str.strip('*'))
        pandas_db.insert(8, 'COUNTY', pandas_db.pop('COUNTY').str.strip('*'))
        pandas_db.insert(9, 'TAXID', pandas_db.pop('TAXID').str.strip('*'))
        pandas_db.insert(10, 'MLSNUM', pandas_db.pop('MLSNUM'))
        pandas_db.insert(11, 'LOTSIZE', pandas_db.pop('LOTSIZE').str.strip('*'))
        pandas_db.insert(12, 'LOTDESC', pandas_db.pop('LOTDESC'))
        pandas_db.insert(13, 'VARIANCE NEEDED', pandas_db.pop('VARIANCE NEEDED'))
        pandas_db.insert(14, 'Z-SCORE', pandas_db.pop('Z-SCORE'))
        pandas_db.insert(15, 'ORIGLISTPRICE', pandas_db.pop('ORIGLISTPRICE'))
        pandas_db.insert(16, 'LISTPRICE', pandas_db.pop('LISTPRICE'))
        pandas_db.insert(17, 'SALESPRICE', pandas_db.pop('SALESPRICE'))
        pandas_db.insert(18, 'SPLP', pandas_db.pop('SPLP'))

        # List item 3
        pandas_db.insert(7, 'TOWN', pandas_db.pop('TOWN').str.rstrip('*(1234567890)'))
        # List item 4 and 8
        pandas_db.insert(20, 'LISTDATE', pd.to_datetime(pandas_db.pop('LISTDATE')))
        pandas_db.insert(21, 'PENDINGDATE', pd.to_datetime(pandas_db.pop('PENDINGDATE')))
        pandas_db.insert(22, 'CLOSEDDATE', pd.to_datetime(pandas_db.pop('CLOSEDDATE')))
        pandas_db.insert(23, 'UNDER CONTRACT LENGTH', pandas_db['CLOSEDDATE'] - pandas_db['PENDINGDATE'])

        # List item 6
        street_num = pandas_db.pop('STREETNUMDISPLAY')
        street_add = pandas_db.pop('STREETNAME')
        pandas_db.insert(3, 'ADDRESS', street_num.str.cat(street_add, join='left', sep=' ')
                         .str.replace(r'Rd$', 'Road', regex=True)
                         .str.replace(r'Ct$', 'Court', regex=True)
                         .str.replace(r'St$', 'Street', regex=True)
                         .str.replace(r'Ave$', 'Avenue', regex=True)
                         .str.replace(r'Dr$', 'Drive', regex=True)
                         .str.replace(r'Ln$', 'Lane', regex=True)
                         .str.replace(r'Pl$', 'Place', regex=True)
                         .str.replace(r'Ter$', 'Terrace', regex=True)
                         .str.replace(r'Hwy$', 'Highway', regex=True)
                         .str.replace(r'Pkwy$', 'Parkway', regex=True)
                         .str.replace(r'Cir$', 'Circle', regex=True))
        pandas_db.insert(6, 'ADDRESS', pandas_db.pop('ADDRESS').str.replace(r'.*', GSMLS.clean_addresses, regex=True))

        return pandas_db

    @staticmethod
    def clean_and_transform_data_mul(pandas_db, mls, qtr):
        """
        Cleaning that needs to be done
        1. Filter for columns that I want displayed
        2. Remove the asterics attached to the following columns:
            BLOCKID, COUNTY, LOTSIZE, LOTID, STREETNAME
        3. Remove the *(NNNN*) from the town name
        4. Make LISTDATE, PENDINGDATE, CLOSEDDATE columns date type
        5. If no POOL, fillna with 'N' and POOLDESC with 'N'
        6. Create ADDRESS column by combining the 'STREETNUMDISPLAY' and 'STREETNAME' columns
        7. Create 'LATITUDE' AND 'LONGITUTDE' columns and fill with 'N/A'. Move columns right before ADDRESS column
        8. Add a column named "UC-Days" which calculates the total days between going under contract and closing
            # Can be vectorized by doing db['UC-Days'] = db['Closing Date'] - db['Under Contract']
        9. Convert all the values in the LOTSIZE column to sqft. Use Pandas str methods
        :param pandas_db:
        :param mls:
        :param qtr:
        :return:
        """

        pandas_db['SQFTBLDG'] = pandas_db['SQFTBLDG'].fillna(0)
        pandas_db['RENOVATED'] = pandas_db['RENOVATED'].fillna(0)

        pandas_db = pandas_db.astype({'STREETNUMDISPLAY': 'string', 'STREETNAME': 'string',
                                      'RENOVATED': 'int64', 'ORIGLISTPRICE': 'int64',
                                      'LISTPRICE': 'int64', 'SALESPRICE': 'int64', 'SQFTBLDG': 'int64',
                                      'LOTSIZE': 'string', 'MLSNUM': 'string',
                                      'BLOCKID': 'string', 'LOTID': 'string', 'TAXID': 'string'})
        pandas_db.round({'BATHSTOTAL': 1, 'SPLP': 3})

        # List item 2
        pandas_db['MLS'] = mls
        pandas_db['QTR'] = qtr
        pandas_db['Z-SCORE'] = (pandas_db['SALESPRICE'] - pandas_db['SALESPRICE'].mean()) / pandas_db[
            'SALESPRICE'].std()
        pandas_db.insert(0, 'MLS', pandas_db.pop('MLS'))
        pandas_db.insert(1, 'QTR', pandas_db.pop('QTR'))
        pandas_db.insert(2, 'LATITUDE', 0)
        pandas_db.insert(3, 'LONGITUDE', 0)
        pandas_db.insert(4, 'BLOCKID', pandas_db.pop('BLOCKID').str.strip('*'))
        pandas_db.insert(5, 'LOTID', pandas_db.pop('LOTID').str.strip('*'))
        pandas_db.insert(6, 'STREETNAME', pandas_db.pop('STREETNAME').str.strip('*'))
        pandas_db.insert(7, 'COUNTY', pandas_db.pop('COUNTY').str.strip('*'))
        pandas_db.insert(12, 'LOTSIZE', pandas_db.pop('LOTSIZE').str.strip('*'))
        pandas_db.insert(13, 'LOTDESC', pandas_db.pop('LOTDESC'))
        pandas_db.insert(14, 'SQFTAPPROX', pandas_db.pop('SQFTBLDG'))
        pandas_db.insert(15, 'Z-SCORE', pandas_db.pop('Z-SCORE'))
        pandas_db.insert(16, 'ORIGLISTPRICE', pandas_db.pop('ORIGLISTPRICE'))
        pandas_db.insert(17, 'LISTPRICE', pandas_db.pop('LISTPRICE'))
        pandas_db.insert(18, 'SALESPRICE', pandas_db.pop('SALESPRICE'))
        pandas_db.insert(19, 'SPLP', pandas_db.pop('SPLP'))

        # List item 3
        pandas_db.insert(7, 'TOWN', pandas_db.pop('TOWN').str.rstrip('*(1234567890)'))
        # List item 4 and 8
        pandas_db.insert(26, 'LISTDATE', pd.to_datetime(pandas_db.pop('LISTDATE')))
        pandas_db.insert(27, 'PENDINGDATE', pd.to_datetime(pandas_db.pop('PENDINGDATE')))
        pandas_db.insert(28, 'CLOSEDDATE', pd.to_datetime(pandas_db.pop('CLOSEDDATE')))
        pandas_db.insert(29, 'UNDER CONTRACT LENGTH', pandas_db['CLOSEDDATE'] - pandas_db['PENDINGDATE'])

        # List item 6
        street_num = pandas_db.pop('STREETNUMDISPLAY')
        street_add = pandas_db.pop('STREETNAME')
        pandas_db.insert(3, 'ADDRESS', street_num.str.cat(street_add, join='left', sep=' ')
                         .str.replace(r'Rd$', 'Road', regex=True)
                         .str.replace(r'Ct$', 'Court', regex=True)
                         .str.replace(r'St$', 'Street', regex=True)
                         .str.replace(r'Ave$', 'Avenue', regex=True)
                         .str.replace(r'Dr$', 'Drive', regex=True)
                         .str.replace(r'Ln$', 'Lane', regex=True)
                         .str.replace(r'Pl$', 'Place', regex=True)
                         .str.replace(r'Ter$', 'Terrace', regex=True)
                         .str.replace(r'Hwy$', 'Highway', regex=True)
                         .str.replace(r'Pkwy$', 'Parkway', regex=True)
                         .str.replace(r'Cir$', 'Circle', regex=True))
        pandas_db.insert(6, 'ADDRESS', pandas_db.pop('ADDRESS').str.replace(r'.*', GSMLS.clean_addresses, regex=True))

        return pandas_db

    @staticmethod
    def clean_and_transform_data_res(pandas_db, mls, qtr, median_sales):
        """
        Cleaning that needs to be done
        1. Filter for columns that I want displayed
        2. Remove the asterics attached to the following columns:
            BLOCKID, COUNTY, LOTSIZE, LOTID, STREETNAME
        3. Remove the *(NNNN*) from the town name
        4. Make LISTDATE, PENDINGDATE, CLOSEDDATE columns date type
        5. If no POOL, fillna with 'N' and POOLDESC with 'N'
        6. Create ADDRESS column by combining the 'STREETNUMDISPLAY' and 'STREETNAME' columns
        7. Create 'LATITUDE' AND 'LONGITUTDE' columns and fill with 'N/A'. Move columns right before ADDRESS column
        8. Add a column named "UC-Days" which calculates the total days between going under contract and closing
            # Can be vectorized by doing db['UC-Days'] = db['Closing Date'] - db['Under Contract']
        9. Convert all the values in the LOTSIZE column to sqft. Use Pandas str methods
        :param pandas_db:
        :param mls:
        :param qtr:
        :param median_sales:

        :return:
        """

        pandas_db['SQFTAPPROX'] = pandas_db['SQFTAPPROX'].fillna(0)
        pandas_db['RENOVATED'] = pandas_db['RENOVATED'].fillna(0)
        pandas_db = pandas_db.astype({'STREETNUMDISPLAY': 'string', 'STREETNAME': 'string',
                                      'SQFTAPPROX': 'int64', 'RENOVATED': 'int64', 'ORIGLISTPRICE': 'int64',
                                      'LISTPRICE': 'int64', 'SALESPRICE': 'int64', 'LOTSIZE': 'string',
                                      'MLSNUM': 'string', 'BLOCKID': 'string', 'LOTID': 'string', 'TAXID': 'string'})
        pandas_db.round({'BATHSTOTAL': 1, 'SPLP': 3})

        # List item 2
        pandas_db['MLS'] = mls
        pandas_db['QTR'] = qtr
        pandas_db['Z-SCORE'] = (pandas_db['SALESPRICE'] - median_sales[0]) / median_sales[1]
        pandas_db.insert(0, 'MLS', pandas_db.pop('MLS'))
        pandas_db.insert(1, 'QTR', pandas_db.pop('QTR'))
        pandas_db.insert(2, 'LATITUDE', 0)
        pandas_db.insert(3, 'LONGITUDE', 0)
        pandas_db.insert(4, 'BLOCKID', pandas_db.pop('BLOCKID').str.strip('*'))
        pandas_db.insert(5, 'LOTID', pandas_db.pop('LOTID').str.strip('*'))
        pandas_db.insert(6, 'STREETNAME', pandas_db.pop('STREETNAME').str.strip('*'))
        pandas_db.insert(7, 'COUNTY', pandas_db.pop('COUNTY').str.strip('*'))
        pandas_db.insert(11, 'SQFTAPPROX', pandas_db.pop('SQFTAPPROX'))
        pandas_db.insert(13, 'LOTSIZE', pandas_db.pop('LOTSIZE').str.strip('*'))
        pandas_db.insert(14, 'LOTDESC', pandas_db.pop('LOTDESC'))
        pandas_db.insert(18, 'Z-SCORE', pandas_db.pop('Z-SCORE'))

        # List item 3
        pandas_db.insert(7, 'TOWN', pandas_db.pop('TOWN').str.rstrip('*(1234567890)'))
        # List item 4 and 8
        pandas_db.insert(26, 'LISTDATE', pd.to_datetime(pandas_db.pop('LISTDATE')))
        pandas_db.insert(27, 'PENDINGDATE', pd.to_datetime(pandas_db.pop('PENDINGDATE')))
        pandas_db.insert(28, 'CLOSEDDATE', pd.to_datetime(pandas_db.pop('CLOSEDDATE')))
        pandas_db.insert(29, 'UNDER CONTRACT LENGTH', pandas_db['CLOSEDDATE'] - pandas_db['PENDINGDATE'])
        # List item 5
        pandas_db["POOL"].fillna('N')
        pandas_db["POOLDESC"].fillna('N')
        # List item 6
        street_num = pandas_db.pop('STREETNUMDISPLAY')
        street_add = pandas_db.pop('STREETNAME')
        pandas_db.insert(3, 'ADDRESS', street_num.str.cat(street_add, join='left', sep=' ')
                         .str.replace(r'Rd$|Rd\.$', 'Road', regex=True)
                         .str.replace(r'Ct$|Ct\.$', 'Court', regex=True)
                         .str.replace(r'St$|St\.$', 'Street', regex=True)
                         .str.replace(r'Ave$|Ave\.$', 'Avenue', regex=True)
                         .str.replace(r'Dr$|Dr\.$', 'Drive', regex=True)
                         .str.replace(r'Ln$|Ln\.$', 'Lane', regex=True)
                         .str.replace(r'Pl$|Pl\.$', 'Place', regex=True)
                         .str.replace(r'Ter$|Ter\.$', 'Terrace', regex=True)
                         .str.replace(r'Hwy$|Hwy\.$', 'Highway', regex=True)
                         .str.replace(r'Pkwy$|Pkwy\.$', 'Parkway', regex=True)
                         .str.replace(r'Cir$|Cir\.$', 'Circle', regex=True))
        pandas_db.insert(6, 'ADDRESS', pandas_db.pop('ADDRESS').str.replace(r'.*', GSMLS.clean_addresses, regex=True))

        return pandas_db


    @staticmethod
    @logger_decorator
    def clean_db(**kwargs):
        """
        This function accepts a Pandas database to:
        Step 1: clean and transform all data into uniform datatypes before being transferred into a SQL database
        Step 2: Fortifies the data with all the proper living space sq_ft
        Step 3: Converts all lot size values to sq_ft

        :param dirty_db:
        :param tax_db:
        :param property_type:
        :param qtr:
        :return:
        """

        dirty_db = kwargs['initial_db']
        # tax_db = kwargs['tax_db']
        property_type = kwargs['property_type']
        mls_type = kwargs['mls_type']
        qtr = kwargs['qtr']
        median_sales_prices = kwargs['median_sales_price']

        target_columns = ['TAXID', 'MLSNUM', 'BLOCKID', 'LOTID', 'STREETNUMDISPLAY', 'STREETNAME', 'TOWN', 'COUNTY',
                          'ROOMS', 'BEDS', 'BATHSTOTAL', 'LOTSIZE', 'LOTDESC', 'SQFTAPPROX', 'ORIGLISTPRICE', 'LISTPRICE',
                          'SALESPRICE', 'SPLP', 'LOANTERMS', 'YEARBUILT', 'YEARBUILTDESC', 'STYLEPRIMARY',
                          'PROPCOLOR', 'RENOVATED',  'TAXAMOUNT', 'TAXRATE', 'LISTDATE', 'PENDINGDATE',
                          'CLOSEDDATE', 'DAYSONMARKET', 'OFFICENAME', 'OFFICEPHONE', 'FAX',
                          'AGENTNAME', 'AGENTPHONE', 'COMPBUY', 'SELLOFFICENAME', 'SELLAGENTNAME', 'FIREPLACES',
                          'GARAGECAP', 'POOL', 'POOLDESC', 'BASEMENT', 'BASEDESC', 'AMENITIES', 'APPLIANCES', 'COOLSYSTEM',
                          'DRIVEWAYDESC', 'EXTERIOR', 'FLOORS', 'HEATSRC', 'HEATSYSTEM', 'ROOF',
                          'SIDING', 'SEWER', 'WATER', 'WATERHEATER', 'ROOMLVL1DESC', 'ROOMLVL2DESC', 'ROOMLVL3DESC',
                          'REMARKSPUBLIC']

        if property_type == 'RES':
            clean_db = dirty_db[target_columns].fillna(np.nan)
            clean_db = clean_db.pipe(GSMLS.clean_and_transform_data_res, mls=mls_type, qtr=qtr, median_sales=median_sales_prices)\
                .pipe(GSMLS.find_sq_ft, **kwargs)\
                .pipe(GSMLS.convert_lot_size, property_type=property_type)

        elif property_type == 'MUL':
            temp_target_columns = [column for column in target_columns if column not in ['POOL', 'POOLDESC',
                                    'SQFTAPPROX', 'STYLEPRIMARY', 'FIREPLACES', 'AMENITIES', 'APPLIANCES',
                                    'FLOORS', 'ROOMLVL1DESC', 'ROOMLVL2DESC', 'ROOMLVL3DESC']]
            temp_target_columns.extend(['UNIT1BATHS', 'UNIT1BEDS', 'UNIT2BATHS', 'UNIT2BEDS', 'UNIT3BATHS', 'UNIT3BEDS',
                                   'UNIT4BATHS', 'UNIT4BEDS', 'SQFTBLDG'])
            clean_db = dirty_db[temp_target_columns].fillna(np.nan)
            clean_db = clean_db.pipe(GSMLS.clean_and_transform_data_mul, mls=mls_type, qtr=qtr)\
                .pipe(GSMLS.find_sq_ft, **kwargs)\
                .pipe(GSMLS.total_units).pipe(GSMLS.convert_lot_size, property_type=property_type)

        elif property_type == 'LND':
            remove_columns = ['ROOMS', 'BEDS', 'BATHSTOTAL', 'YEARBUILT', 'POOLDESC', 'SQFTAPPROX',
                              'YEARBUILTDESC', 'STYLEPRIMARY', 'PROPCOLOR', 'RENOVATED', 'FIREPLACES',
                              'GARAGECAP', 'POOL', 'BASEMENT', 'BASEDESC', 'AMENITIES', 'APPLIANCES', 'COOLSYSTEM',
                              'DRIVEWAYDESC', 'EXTERIOR', 'FLOORS', 'HEATSRC', 'HEATSYSTEM', 'ROOF',
                              'SIDING', 'SEWER', 'WATER', 'WATERHEATER', 'ROOMLVL1DESC', 'ROOMLVL2DESC',
                              'ROOMLVL3DESC', 'POOL']
            temp_target_columns = [column for column in target_columns if column not in remove_columns]
            temp_target_columns.extend(['NUMLOTS', 'ZONING', 'BUILDINGSINCLUDED', 'CURRENTUSE', 'DEVSTATUS', 'DOCSAVAIL',
                                   'EASEMENT', 'FLOODINSUR', 'FLOODZONE', 'IMPROVEMENTS', 'LOCATION',
                                   'PERCTEST', 'ROADSURFACEDESC', 'SERVICES', 'SEWERINFO', 'SOILTYPE', 'WATERINFO',
                                   'ZONINGDESC'])
            clean_db = dirty_db[temp_target_columns].fillna(np.nan)
            clean_db = clean_db.pipe(GSMLS.clean_and_transform_data_lnd, mls=mls_type, qtr=qtr)\
                .pipe(GSMLS.convert_lot_size, property_type=property_type)

        return clean_db


    def comps(self, property_address, br=None, bth=None, sq_ft=None, home_type=None):
        """
        Method which accepts a property address as an expected argument. Other expected agruments with a default
        value of None but if given, can help better narrow the comps.
        I need to be able to animate the GSMLS map tool so I can find all comps within a mile
        Follow the NABPOPs Guidelines for Comparables to ensure the model gives the best comps.
        The following ideas need to be included:
        - Guidelines for comps
        - Lack of comps
        - Market Considerations
        - Rating Property/Amenities
        - Adjustment features
        - Land Value

        TRANSFORM THE DATABASE TO HAVE COLUMN NAMES AS THE INDEX AND THE PROPERTY NAMES AS THE COLUMN NAMES!!!

        :param property_address:
        :param br:
        :param bth:
        :param sq_ft:
        :param home_type:
        :return:
        """

        pass

    @staticmethod
    def connect2postgresql():

        # Do I create a function which retrieve my info from UniversalFunction.get_us_pw?
        '''
        database: the name of the database that you want to connect.
        user: the username used to authenticate.
        password: password used to authenticate.
        host: database server address e.g., localhost or an IP address.
        port: the port number that defaults to 5432 if it is not provided.
        '''

        username, pw = GSMLS.get_us_pw('PostgreSQL')

        conn = psycopg2.connect(
            host="localhost",
            database="nj_realestate_data",
            user=username,
            password=pw)

        cur = conn.cursor()

        return tuple([cur, conn, username, pw])

    @staticmethod
    def convert_lot_size(db, property_type):
        """

        :param db:
        :param property_type:
        :return:
        """

        lotsize_sqft = db['LOTSIZE']

        if property_type == 'RES':
            db.insert(13, 'LOTSIZE (SQFT)', GSMLS.fix_lotsize(lotsize_sqft))

        elif property_type == 'MUL':
            db.insert(13, 'LOTSIZE (SQFT)', GSMLS.fix_lotsize(lotsize_sqft))

        elif property_type == 'LND':
            db.insert(13, 'LOTSIZE (SQFT)', GSMLS.fix_lotsize(lotsize_sqft))

        # db = db.astype({'LOTSIZE (SQFT)': 'float64'})
        db = db.round({'LOTSIZE (SQFT)': 2})

        return db
    @staticmethod
    def find_sq_ft(db, tax_db, **kwargs):
        """
        This function loops through each individual address in the respective address database and tries
        to assign the sq_ft value found in the tax database
        :param db:
        :param tax_db:
        :return:
        """

        numbers_dict = {'1ST': 'FIRST', 'FIRST': '1ST', '2ND': 'SECOND', 'SECOND': '2ND',
                        '3RD': 'THIRD', 'THIRD': '3RD', '4TH': 'FOURTH', 'FOURTH': '4TH',
                        '5TH': 'FIFTH', 'FIFTH': '5TH', '6TH': 'SIXTH', 'SIXTH': '6TH',
                        '7TH': 'SEVENTH', 'SEVENTH': '7TH', '8TH': 'EIGHTH', 'EIGHTH': '8TH',
                        '9TH': 'NINTH', 'NINTH': '9TH', '10TH': 'TENTH', 'TENTH': '10TH'}

        if tax_db is not None:

            address_list = db['ADDRESS'].to_list()
            tax_address_list = tax_db['Property Location'].to_list()

            db.set_index('ADDRESS', inplace=True, drop=False)
            tax_db.set_index('Property Location', inplace=True, drop=False)  # Column would still need to be indexed in the event of a ValueError so leave duplicate
            numbered_blocks = re.compile(
                r'\d{1,2}?st|\d{1,2}?nd|\d{1,2}?rd|\d{1,2}?th|First|Second|Third|Fourth|Fifth|Sixth|Seventh|Eighth|Nineth|Tenth')

            for address in address_list:
                search_address = numbered_blocks.search(address, re.IGNORECASE)
                if search_address is None:

                    db = GSMLS.sq_ft_search(address, db, tax_db, tax_address_list, **kwargs)

                elif search_address is not None:
                    # Check if the current spelling of the address is the same as in the tax_tb
                    if address.upper() in tax_address_list:

                        db = GSMLS.sq_ft_search(address, db, tax_db, tax_address_list, **kwargs)

                    else:
                        # Change the spelling of the address and check tax_db again
                        address_2 = address.replace(search_address.group(0), numbers_dict[search_address.group(0).upper()])

                        db = GSMLS.sq_ft_search(address, db, tax_db, tax_address_list, address_2, **kwargs)
        else:
            # find_sq_ft cannot be run without a tax_db
            pass

        return db

    @staticmethod
    def fix_lotsize(series):
        """

        :param series:
        :return:
        """
        acres = re.compile(r'((\d{1,4})?\.\d{1,6}(\s)?AC(\.)?(RE(S)?)?|(\d{1,4})?\.\d{1,6}(\s)?acs(\.)?)',
                           flags=re.IGNORECASE)
        l_w_1 = re.compile(r'(\d{1,4}(\.\d{1,5})?)(\s)?X(\s)?(\d{1,4}(\.\d{1,5})?)((\s)?[A-Z.]*[0-9]*)*',
                           flags=re.IGNORECASE)
        sq_ft_p = r'((\d{1,3}?,)?\d{1,7}?(\.\d{1,5})?(\s)?SF)'
        acres_unconventional = r'((\d{1,3})?\.\d{1,7})'
        # mixed_pattern = ((\d{1,4})?\.\d{1,6})(\s)?((\d{1,4}(\.\d{1,5})?)(\s)?X(\s)?(\d{1,4}(\.\d{1,5})?)((\s)?[A-Z.]*[0-9]*)*)
        pattern_list = [acres, acres_unconventional, l_w_1, sq_ft_p]

        sum_series = 0
        for p in pattern_list:
            findings = series.where(series.str.fullmatch(p))
            if p == l_w_1:
                target1 = findings.str.replace(p, GSMLS.length_and_width_to_sqft, regex=True).fillna('0')
                target1 = target1.astype('float64')

            elif p == acres or acres_unconventional:
                target1 = findings.str.replace(p, GSMLS.acres_to_sqft, regex=True).fillna('0')
                target1 = target1.astype('float64')

            elif p == sq_ft_p:
                target1 = findings.str.replace(p, GSMLS.sq_ft_pattern_clean, regex=True).fillna('0')
                target1 = target1.astype('float64')

            sum_series += target1

        return sum_series
    @logger_decorator
    def lat_long(self, db, county=None, city=None, **kwargs):
        """
        Function used to find a property's latitude and longitude values to calculate the distance from the target
        property
        :param db:
        :param county:
        :param city:
        :param kwargs:
        :return:
        """
        # Fortifies a current df of properties with the longitude and latitude info
        # to be used to calculate the distance between a target property and the comp
        # Use https://www.latlong.net/

        logger = kwargs['logger']
        f_handler = kwargs['f_handler']
        c_handler = kwargs['c_handler']

        # counties = NJTaxAssessment.state_county_dictionary()
        good_property_pattern = re.compile(r'(\d{1,5}?-\d{1,5}?|\d{1,5}?)\s(.*)')
        bad_property_pattern = re.compile(r'^[a-zA-Z]')
        url = 'https://geocode.maps.co/search?q='

        try:
            property_address_list = db['ADDRESS'].to_list()
            db = db.set_index('ADDRESS')
            for i in property_address_list:
                if bad_property_pattern.search(i):
                    continue
                elif good_property_pattern.search(i):
                    if (db.loc[i, 'LATITUDE'] or db.loc[i, 'LONGITUDE']) == 0:
                        raw_addr = i
                        address = '+'.join(raw_addr.split(' '))
                        city = db.loc[i, 'TOWN']
                        state = 'NJ'

                        true_url = url + '+'.join([address, city, state])
                        response = requests.get(true_url)  # Be sure to use the proxies in the requests
                        json_results = response.json()

                        if len(json_results) > 1:
                            db.at[i, 'LATITUDE'] = float(json_results[0]['lat'])
                            db.at[i, 'LONGITUDE'] = float(json_results[0]['lon'])
                            time.sleep(1.5)  # Self throttling to not throw the HTTP 429 response
                        else:
                            db.at[i, 'LATITUDE'] = float(json_results['lat'])
                            db.at[i, 'LONGITUDE'] = float(json_results['lon'])
                            time.sleep(1.5)  # Self throttling to not throw the HTTP 429 response
                    else:
                        continue

        # I need to put Request modules exceptions here
        except Exception as e:
            print(e)

        else:
            logger.removeHandler(f_handler)
            logger.removeHandler(c_handler)
            logging.shutdown()

            return db

    @staticmethod
    def length_and_width_to_sqft(search_string):
        try:
            if search_string.group(1) is not None:
                return str((float(search_string.group(1)) * float(search_string.group(5))))
            else:
                raise TypeError
        except TypeError as te:
            print(f'{traceback.print_tb(te.__traceback__)}')




        def paired_sales_analysis(self, city):

        """
        Run a feature valuation or paired sales analysis for features of homes to know what adjustments to make
        when running comparibles
        :param city:
        :return:
        """
        pass

        @staticmethod
    def quarterly_appr_depr(county, city, quarter):
        """
        Method which calculates the quarterly neighborhood appreciation/depreciation based on homes gross livable
        area (GLA), homes prices and dates.
        Need to use a minimum of 30 homes minimum. Save this information in the same file as quarterly_sales
        :param county:
        :param city:
        :param quarter:
        :return:
        """

        base_path = 'F\.........'

        quarter_list = ['Q1', 'Q2', 'Q3', 'Q4']

        os.chdir(base_path)
        year = datetime.today().year
        filename = os.path.join(base_path, county, city, city + ' ' + quarter + ' ' + str(year) + ' ' + 'Sales')

        if os.path.exists(filename):
            db1 = pd.read_excel(filename)
            if quarter == 'Q1':
                previous_qtr = 'Q4'
                db2 = pd.read_excel(os.path.join(base_path, county, city,
                                                 city + ' ' + previous_qtr + ' ' + str(year - 1) + ' ' + 'Sales'))
            else:
                db2 = pd.read_excel(os.path.join(base_path, county, city,
                                             city + ' ' + quarter_list[quarter_list.index(quarter) - 1] + ' ' + str(
                                                 year - 1) + ' ' + 'Sales'))
        else:
            raise AttributeError or IOError

            #  Run calculations



    @staticmethod
    def total_units(db):

        temp_db = db
        temp_db = temp_db.astype({'UNIT1BATHS': 'string', 'UNIT2BATHS': 'string',
                             'UNIT3BATHS': 'string', 'UNIT4BATHS': 'string'})

        temp_dict = {
            'unit1': temp_db['UNIT1BATHS'].str.replace(r'\d{1}|\d{1}.\d{1,30}?', '1', regex=True)
            .str.replace('np.nan', '0'),
            'unit2': temp_db['UNIT2BATHS'].str.replace(r'\d{1}|\d{1}.\d{1,30}?', '1', regex=True)
            .str.replace('np.nan', '0'),
            'unit3': temp_db['UNIT3BATHS'].str.replace(r'\d{1}|\d{1}.\d{1,30}?', '1', regex=True)
            .str.replace('np.nan', '0'),
            'unit4': temp_db['UNIT4BATHS'].str.replace(r'\d{1}|\d{1}.\d{1,30}?', '1', regex=True)
            .str.replace('np.nan', '0')
        }

        temp_db2 = pd.DataFrame(temp_dict).fillna(value='0')
        temp_db2 = temp_db2.astype({'unit1': 'int64', 'unit2': 'int64', 'unit3': 'int64', 'unit4': 'int64'})

        db['TOTALUNITS'] = temp_db2['unit1'] + temp_db2['unit2'] + temp_db2['unit3'] + temp_db2['unit4']

        db.insert(6, 'TOTALUNITS', db.pop('TOTALUNITS'))

        return db

    @staticmethod
    def tax_db_notfound(county_var, cityname_var, **kwargs):

        logger = kwargs['logger']

        # Modified var city_name isn't equivalent to the tax_db directory folder name
        try:
            tax_db = NJTaxAssessment.city_database(county_var, cityname_var)
            tax_db.set_index('Property Location')
        except FileNotFoundError:

            if county_var == 'Ocean':
                # Municipalities located in Ocean County don't have tax_dbs.
                # For cities located in these counties, set tax_db = None
                tax_db = None

            else:
                # City_name2 isn't equivalent to the tax_db directory folder name
                temp_var = cityname_var.split(' ')
                if temp_var[-1] == 'Twp':
                    temp_var[-1] = 'Township'
                elif temp_var[-1] == 'Boro':
                    temp_var[-1] = 'Borough'

                city_name3 = ' '.join(temp_var)
                try:
                    tax_db = NJTaxAssessment.city_database(county_var, city_name3)
                    tax_db.set_index('Property Location')
                except FileNotFoundError:
                    # There is no tax_db available for this city_name. Look into this error further if
                    # encountered. Create logger message to capture this error
                    logger.warning(f'There is no tax_db available for {cityname_var}.')
                    tax_db = None

        finally:

            return tax_db

    @staticmethod
    def sq_ft_keyerror(mls_address, mls_db, tax_db, outer_address_list, **kwargs):
        """

        :param mls_address:
        :param mls_db:
        :param tax_db:
        :param outer_address_list:
        :param kwargs:
        :return:
        """

        logger = kwargs['logger']

        change_dict = {'Rd': 'Road', 'Ct': 'Court', 'St': 'Street', 'Ave': 'Avenue',
                       'Dr': 'Drive', 'Ln': 'Lane', 'Pl': 'Place', 'Ter': 'Terrace', 'Hwy': 'Highway',
                       'Pkwy': 'Parkway', 'Cir': 'Circle'}
        clean_pattern = re.compile(r'(Rd$|Ct$|St$|Ave$|Dr$|Ln$|Pl$|Ter$|Hwy$|Pkwy$|Cir$)', flags=re.IGNORECASE)
        space_pattern = re.compile(r'(\xa0)')
        address_pattern = re.compile(r'(.*)')
        mls_number = str(mls_db.loc[mls_address, 'MLSNUM'])
        address_list = GSMLS.property_archive(mls_number, mls_address, **kwargs)

        if address_list == f'No historical addresses available for MLS#:{mls_number}':
            logger.info(f'There are no historical addresses available for {mls_address}')
            for idx, addy1 in enumerate(outer_address_list):
                if mls_address[:10].upper() in addy1:
                    final_address = outer_address_list[idx]
                    logger.info(f'Partial match for {addy1} found in outer list. Sqft can now be found\n')

                    return GSMLS.sq_ft_search(mls_address, mls_db, tax_db, outer_address_list,
                                              transformed_address=final_address, **kwargs)

                elif (mls_address[:10].upper() not in addy1) and (addy1 != outer_address_list[-1]):
                    continue

                elif (mls_address[:10].upper() not in addy1) and (addy1 == outer_address_list[-1]):

                    if int(mls_db.loc[mls_address, 'SQFTAPPROX']) > 0:
                        pass

                    else:
                        # No address works
                        logger.info(
                            f'None of the addresses meets the database search criteria. Now initiating the RPR function.')
                        full_address = mls_address + ', ' + mls_db.loc[mls_address, 'TOWN'].split(' ')[0]
                        rpr_results = GSMLS.rpr('SQFT', full_address, **kwargs)
                        if rpr_results > 0:
                            logger.info(f'RPR sqft results for {mls_address} have been found: {rpr_results}\n')
                            mls_db.at[mls_address, 'SQFTAPPROX'] = rpr_results

                        elif int(mls_db.loc[mls_address, 'SQFTAPPROX']) > 0:
                            pass

                        else:
                            logger.info(f'RPR sqft results for {mls_address} have not been found\n')
                            mls_db.at[mls_address, 'SQFTAPPROX'] = 0
        else:
            logger.info(f'A list of addresses similar to {mls_address} have been found. Looping through the list until an address which matches the criteria is found')
            for addy in address_list:
                try:
                    space_search = space_pattern.search(addy).group()
                    space_found = addy.replace(space_search, ' ')
                    change_search = clean_pattern.search(space_found).group()
                    # change_found = space_found.replace(change_search, change_dict[change_search.title()])
                    change_found = change_dict[change_search.title()].join(space_found.rsplit(change_search, maxsplit=1))
                    address_search = address_pattern.search(change_found)
                    final_address = GSMLS.clean_addresses(address_search)

                except AttributeError:
                    if addy != list(address_list)[-1]:
                        logger.info(f'{addy} does not meet the database search criteria. Continuing through the loop')
                        continue

                    elif addy.upper() not in outer_address_list:
                        space_search = space_pattern.search(addy).group()
                        space_found = addy.replace(space_search, ' ')
                        for idx, addy1 in enumerate(outer_address_list):
                            if space_found[:10].upper() in addy1:
                                final_address = outer_address_list[idx]
                                logger.info(f'Partial match for {addy} found in outer list. Sqft can now be found\n')

                                return GSMLS.sq_ft_search(mls_address, mls_db, tax_db, outer_address_list,
                                                          transformed_address=final_address, **kwargs)

                            elif (space_found[:10].upper() not in addy1) and (addy1 != outer_address_list[-1]):
                                continue

                            elif (space_found[:10].upper() not in addy1) and (addy1 == outer_address_list[-1]):

                                if int(mls_db.loc[mls_address, 'SQFTAPPROX']) > 0:
                                    pass

                                else:
                                    # No address works
                                    logger.info(f'None of the addresses meets the database search criteria. Now initiating the RPR function.')
                                    full_address = addy.title() + ', ' + mls_db.loc[mls_address, 'TOWN'].split(' ')[0]
                                    rpr_results = GSMLS.rpr('SQFT', full_address, **kwargs)
                                    if rpr_results > 0:
                                        logger.info(f'RPR sqft results for {mls_address} have been found: {rpr_results}\n')
                                        mls_db.at[mls_address, 'SQFTAPPROX'] = rpr_results

                                    elif int(mls_db.loc[mls_address, 'SQFTAPPROX']) > 0:
                                        pass

                                    else:
                                        logger.info(f'RPR sqft results for {mls_address} have not been found\n')
                                        mls_db.at[mls_address, 'SQFTAPPROX'] = 0

                else:

                    if final_address.upper() in outer_address_list:
                        logger.info(f'{final_address} meets the database search criteria\n')

                        return GSMLS.sq_ft_search(mls_address, mls_db, tax_db, outer_address_list,
                                                  transformed_address=final_address, **kwargs)
                    elif final_address.upper() not in outer_address_list:

                        for idx, addy1 in enumerate(outer_address_list):
                            if final_address[:10].upper() in addy1:
                                final_address = outer_address_list[idx]
                                logger.info(f'Partial match for {final_address} found in outer list. Sqft can now be found\n')

                                return GSMLS.sq_ft_search(mls_address, mls_db, tax_db, outer_address_list,
                                                          transformed_address=final_address, **kwargs)

                            elif (space_found[:10].upper() not in addy1) and (addy1 != outer_address_list[-1]):
                                continue

                            elif (space_found[:10].upper() not in addy1) and (addy1 == outer_address_list[-1]):

                                if addy != list(address_list)[-1]:
                                    continue

                                elif int(mls_db.loc[mls_address, 'SQFTAPPROX']) > 0:
                                    pass

                                else:
                                    # No address works
                                    logger.info(
                                        f'None of the addresses meets the database search criteria. Now initiating the RPR function.')
                                    full_address = addy.title() + ', ' + mls_db.loc[mls_address, 'TOWN']
                                    rpr_results = GSMLS.rpr('SQFT', full_address)
                                    if rpr_results > 0:
                                        logger.info(f'RPR sqft results for {mls_address} have been found: {rpr_results}\n')
                                        mls_db.at[mls_address, 'SQFTAPPROX'] = rpr_results

                                    elif int(mls_db.loc[mls_address, 'SQFTAPPROX']) > 0:
                                        pass

                                    else:
                                        logger.info(f'RPR sqft results for {mls_address} have not been found\n')
                                        mls_db.at[mls_address, 'SQFTAPPROX'] = 0

        return mls_db

    @staticmethod
    def sq_ft_pattern_clean(search_string):
        if ',' in search_string.group(1):
            return str(float(''.join(search_string.group(1).split(',')).rstrip(' SF.')))
        else:
            return str(float(search_string.group(1).rstrip(' SF.')))

    @staticmethod
    def sq_ft_search(mls_address, mls_db, tax_db, outer_address_list, transformed_address=None, **kwargs):

        logger = kwargs['logger']
        f_handler = kwargs['f_handler']
        c_handler = kwargs['c_handler']

        if transformed_address is None:
            # Sq ft search for non numbered blocks
            try:
                if mls_db.loc[mls_address, 'SQFTAPPROX'] == 0:
                    mls_db.at[mls_address, 'SQFTAPPROX'] = tax_db.loc[mls_address.upper(), 'Sq. Ft.']
                elif mls_db.loc[mls_address, 'SQFTAPPROX'] != 0:
                    if mls_db.loc[mls_address, 'SQFTAPPROX'] == tax_db.loc[mls_address.upper(), 'Sq. Ft.']:
                        pass
                    elif (tax_db.loc[mls_address.upper(), 'Sq. Ft.'] == 0) and int(
                            mls_db.loc[mls_address, 'SQFTAPPROX']) > 0:
                        pass
                    else:
                        mls_db.at[mls_address, 'SQFTAPPROX'] = tax_db.loc[mls_address.upper(), 'Sq. Ft.']

            except ValueError:
                logger.info(f'Multiple addresses @ {mls_address} have been found. The search will be narrowed to find the correct one')
                year_built = mls_db.loc[mls_address, 'YEARBUILT']
                tax_db = tax_db[(tax_db['Yr. Built'] == year_built) & (tax_db['Property Location'] == mls_address.upper())]

                return GSMLS.sq_ft_search(mls_address, mls_db, tax_db, outer_address_list, **kwargs)

            except KeyError:
                logger.warning(f'{mls_address} was not found in the tax database. Sq_ft_keyerror will be initiated to find the correct address')

                return GSMLS.sq_ft_keyerror(mls_address, mls_db, tax_db, outer_address_list, **kwargs)

        else:
            # Sq ft search for numbered blocks
            try:
                if mls_db.loc[mls_address, 'SQFTAPPROX'] == 0:
                    mls_db.at[mls_address, 'SQFTAPPROX'] = tax_db.loc[transformed_address.upper(), 'Sq. Ft.']
                elif mls_db.loc[mls_address, 'SQFTAPPROX'] != 0:
                    if mls_db.loc[mls_address, 'SQFTAPPROX'] == tax_db.loc[transformed_address.upper(), 'Sq. Ft.']:
                        pass
                    elif (tax_db.loc[transformed_address.upper(), 'Sq. Ft.'] == 0) and int(
                            mls_db.loc[mls_address, 'SQFTAPPROX']) > 0:
                        pass
                    else:
                        mls_db.at[mls_address, 'SQFTAPPROX'] = tax_db.loc[transformed_address.upper(), 'Sq. Ft.']

            except ValueError:
                logger.info(
                    f'Multiple addresses @ {mls_address} have been found. The search will be narrowed to find the correct one')
                year_built = mls_db.loc[mls_address, 'YEARBUILT']
                tax_db = tax_db[(tax_db['Yr. Built'] == year_built) & (tax_db['Property Location'] == transformed_address.upper())]

                return GSMLS.sq_ft_search(mls_address, mls_db, tax_db, outer_address_list, transformed_address, **kwargs)

            except KeyError:
                logger.warning(
                    f'{mls_address} was not found in the tax database. Sq_ft_keyerror will be initiated to find the correct address')

                return GSMLS.sq_ft_keyerror(mls_address, mls_db, tax_db, outer_address_list, **kwargs)

        return mls_db

    @staticmethod
    def rpr(search_type, full_address, **kwargs):

        driver = kwargs['driver']
        gsmls_window = kwargs['gsmls_window']
        rpr_window = kwargs['rpr_window']

        driver.switch_to.window(rpr_window)
        address_found = GSMLS.rpr_search_address(full_address, driver)

        if address_found:
            if search_type == 'SQFT':
                results = int(GSMLS.rpr_sq_ft(driver))

            elif search_type == 'FULL':
                results = GSMLS.rpr_property_facts(driver)

            driver.switch_to.window(gsmls_window)
            return results

        else:
            driver.switch_to.window(gsmls_window)
            return 0

    @staticmethod
    @logger_decorator
    def rpr_property_facts(driver_var, **kwargs):

        county_html_pattern = re.compile(r'<span\s_ngcontent-ng-.*\sclass="ng-tns-.*">(\w+\sCounty)</span>')
        block_lot_pattern = re.compile(r'<span\s_ngcontent-ng-.*\sclass="ng-tns-.*">(LOT:\d{1,5}?\sBLK:\d{1,5}?\sDIST:\d{1,5}?)')

        property_dict = {}
        page_results = driver_var.page_source
        soup = BeautifulSoup(page_results, 'html.parser')

        property_dict['estimated_value'] = soup.find('div', {"class": "price ng-star-inserted"}).a.get_text()
        property_dict['rvm_last_updated'] = soup.find('div', {
            "class": "footer ng-star-inserted"}).div.div.next_sibling.get_text()
        property_dict['County'] = county_html_pattern.search(str(soup)).group(1)
        property_dict['Block & Lot'] = block_lot_pattern.search(str(soup)).group(1)

        key_facts = soup.find('section', {"class": "key-facts"})
        basic_facts = soup.find('ul', {"class": "has-columns three-columns ng-star-inserted"})
        property_facts = soup.find('table', {"class": "table is-fullwidth is striped details-table"}).tbody
        exterior_features = soup.find_all('ul', {"class": "flex-item-equal-width ng-star-inserted"})

        for idx, item in enumerate(key_facts.find_all('div')):
            if idx == 0:
                property_dict['sq_ft'] = item.get_text()
            elif idx == 1:
                property_dict['lot_size'] = item.get_text()

        for idx1, item1 in enumerate(basic_facts.find_all('div', {"class": "break-word"})):
            if idx1 == 0:
                property_dict['type'] = item1.get_text()
            elif idx1 == 2:
                property_dict['owner_name'] = item1.get_text()

        for idx2, item2 in enumerate(property_facts.find_all('tr', {"class": "ng-star-inserted"})):
            if idx2 in [2, 3, 4, 5]:
                property_dict[item2.td.get_text().strip()] = item2.find('div', {
                    "class": "is-print-only ng-star-inserted"}).get_text()
            else:
                property_dict[item2.td.get_text().strip()] = item2.td.next_sibling.div.get_text()

        for idx3, item3 in enumerate(exterior_features):
            for idx4, item4 in enumerate(item3.find_all('li', {"class": "ng-star-inserted"})):
                if idx3 == 0 and idx4 == 1:
                    property_dict[item4.div.get_text().strip()] = item4.div.next_sibling.span.get_text().strip()

                elif idx3 == 1 and idx4 == 0:
                    property_dict[item4.div.get_text().strip()] = item4.div.next_sibling.span.get_text().strip()

    # I need tro see how I can get the county, block and lot number

        return property_dict

    @staticmethod
    @logger_decorator
    def rpr_search_address(mls_address, driver_var, **kwargs):

        logger = kwargs['logger']
        f_handler = kwargs['f_handler']
        c_handler = kwargs['c_handler']

        time.sleep(1.5)  # Built in latency for sign in page to appear.

        main_page_results = driver_var.page_source
        if '<div class="appcues-skip">' in main_page_results:
            close_button = WebDriverWait(driver_var, 10).until(
                EC.presence_of_element_located((By.XPATH, "//html/body/appcues/modal-container/div/a")))
            close_button.click()

        location = WebDriverWait(driver_var, 10).until(
            EC.presence_of_element_located((By.XPATH, "//input[@placeholder='Enter Address, Place, APN/Tax IDs or Listing IDs']")))
        location.click()
        location.send_keys(mls_address)

        page_results = driver_var.page_source
        soup = BeautifulSoup(page_results, 'html.parser')
        address_matches = soup.find('div', {"class": "ng-star-inserted"})
        suggested_address_list = address_matches.find_all('div', {
            "class": "suggestion-container auto-suggest-item keyboard-nav-suggestion-item ng-star-inserted"})

        if len(suggested_address_list) < 1:
            logger.info(f'{mls_address} not found')

            AC(driver_var).key_down(Keys.CONTROL).send_keys('A').key_up(Keys.CONTROL) \
                .key_down(Keys.BACKSPACE).key_up(Keys.BACKSPACE).perform()

            logger.removeHandler(f_handler)
            logger.removeHandler(c_handler)
            logging.shutdown()

            return False

        else:
            address_part_list = []
            for idx, address in enumerate(suggested_address_list):

                suggested_text = address.div.find_all('b', {"class": "highlighted-text"})

                for idx1 in suggested_text:
                    address_part_list.append(idx1.get_text())

                true_address = ' '.join(address_part_list)

                if true_address == mls_address:
                    logger.info(f'{mls_address} found')
                    click_address = WebDriverWait(driver_var, 10).until(
                        EC.presence_of_element_located((By.XPATH, "(//div[@class='suggestion-container auto-suggest-item keyboard-nav-suggestion-item ng-star-inserted'])[" + str(idx) + "]")))
                    click_address.click()

                    logger.removeHandler(f_handler)
                    logger.removeHandler(c_handler)
                    logging.shutdown()

                    return True

                elif true_address != mls_address:
                    continue

                else:

                    AC(driver_var).key_down(Keys.CONTROL).send_keys('A').key_up(Keys.CONTROL) \
                        .key_down(Keys.BACKSPACE).key_up(Keys.BACKSPACE).perform()

                    logger.removeHandler(f_handler)
                    logger.removeHandler(c_handler)
                    logging.shutdown()

                    return False

    @staticmethod
    def rpr_sq_ft(driver_var):

        page_results = driver_var.page_source
        soup = BeautifulSoup(page_results, 'html.parser')

        key_facts = soup.find('section', {"class": "key-facts"})

        sq_ft = key_facts.div.div.span.get_text()

        return sq_ft

@staticmethod
    def open_property_listing(driver_var, list_of_windows, contact_num, logger):

        driver_var.maximize_window()
        click_mls_number = WebDriverWait(driver_var, 10).until(
            EC.presence_of_element_located((By.ID, 'selcontact' + str(contact_num))))
        click_mls_number.click()

        #  Clicking the MLS number will open up a new window. I need to switch to that window
        time.sleep(2)
        windows_list = driver_var.window_handles
        new_window = [window for window in windows_list if window not in list_of_windows][0]
        driver_var.switch_to.window(new_window)

        time.sleep(2)
        try:
            page_results2 = driver_var.page_source
            soup = BeautifulSoup(page_results2, 'html.parser')
            sidebar_table = soup.find('div', {"class": "side-bar-padding"})
            sidebar_buttons = sidebar_table.find_all('div', {"class": "sidebar-button select"})

        except AttributeError as AE:
            try:
                logger.warning(f'An AttributeError was raised: Full page contents not loaded. Refreshing page')
                driver_var.refresh()
                time.sleep(2)
                page_results2 = driver_var.page_source
                soup = BeautifulSoup(page_results2, 'html.parser')
                sidebar_table = soup.find('div', {"class": "side-bar-padding"})
                sidebar_buttons = sidebar_table.find_all('div', {"class": "sidebar-button select"})
            except AttributeError:
                logger.warning(f'AAttributeError was raised: setting sidebar_buttons to None')
                sidebar_buttons = None
        finally:

            return tuple([new_window, sidebar_buttons])


@staticmethod
    def property_archive(mls_number, mls_address=None, **kwargs):

        logger = kwargs['logger']
        driver = kwargs['driver']
        gsmls_window = kwargs['gsmls_window']
        rpr_window = kwargs['rpr_window']
        open_window_list = [gsmls_window, rpr_window]

        contact_num = 2

        # Type in the MLS number or address. Create own function that's able to use both if necessary
        page_results = GSMLS.search_listing(mls_number, driver, logger)

        # Find the address table
        all_rows = GSMLS.address_table_results(page_results, mls_number, logger)

        if type(all_rows) is bs4.element.ResultSet:
            for row in all_rows:
                if row.td.a['value'] == mls_number:
                    try:
                        new_window, sidebar_buttons = GSMLS.open_property_listing(driver, open_window_list, contact_num, logger)
                        open_window_list.append(new_window)

                        if sidebar_buttons is None:
                            raise KeyError("open_property_listing() experienced UnboundLocalError. Potential addresses couldn't be gathered")

                        else:

                            for button in sidebar_buttons:

                                if button.span['class'][1] == 'fa-history':

                                    return GSMLS.address_list_scrape(driver, logger, mls_number, open_window_list)

                                elif (button.span['class'][1] != 'fa-history') and (button != sidebar_buttons[-1]):
                                    continue

                    except KeyError as KE:

                        logger.warning(f'A KeyError was raised:\n{traceback.format_tb(KE.__traceback__)}')
                        # logger.warning(f'{traceback.print_exc(limit=2, file=sys.stdout)}')
                        # There's no Property Archive. Use RPR program
                        driver.switch_to.window(new_window)
                        driver.close()
                        driver.switch_to.window(gsmls_window)

                        search_listing = WebDriverWait(driver, 10).until(
                            EC.presence_of_element_located((By.ID, 'qcksrchmlstxt')))
                        search_listing.click()

                        AC(driver).key_down(Keys.CONTROL).send_keys('A').key_up(Keys.CONTROL) \
                            .key_down(Keys.BACKSPACE).key_up(Keys.BACKSPACE).perform()

                        return f'No historical addresses available for MLS#:{mls_number}'

                else:
                    contact_num += 1
                    continue

        elif type(all_rows) is str:
            return all_rows
        else:
            raise TypeError

    @staticmethod
    def address_list_scrape(driver_var, logger_var, mls_number, windows_var: list, **kwargs):

        driver_var.maximize_window()
        property_archive = WebDriverWait(driver_var, 20).until(
            EC.presence_of_element_located((By.XPATH, "//span[contains(@class,'fa fa-history fa-lg')]")))
        property_archive.click()
        time.sleep(2)
        windows_list = driver_var.window_handles
        new_window2 = [window for window in windows_list if window not in windows_var][0]
        driver_var.switch_to.window(new_window2)

        time.sleep(2)
        address_list = set()
        page_results3 = driver_var.page_source
        soup = BeautifulSoup(page_results3, 'html.parser')
        # print(soup)
        mls_tables = soup.find_all('table', {"class": "oneline"})

        for table in mls_tables:
            main_table2 = table.find('tbody')
            mls_history = main_table2.find_all('tr')[1]
            address_cell = mls_history.find_all('td')[3]

            address_list.add(address_cell.get_text())

        logger_var.info(f'{len(address_list)} historical addresses have been found for MLS#:{mls_number}')
        driver_var.close()
        driver_var.switch_to.window(windows_var[2])
        driver_var.close()
        driver_var.switch_to.window(windows_var[0])

        search_listing = WebDriverWait(driver_var, 10).until(
            EC.presence_of_element_located((By.ID, 'qcksrchmlstxt')))
        search_listing.click()

        AC(driver_var).key_down(Keys.CONTROL).send_keys('A').key_up(Keys.CONTROL)\
            .key_down(Keys.BACKSPACE).key_up(Keys.BACKSPACE).perform()

        return address_list

    @staticmethod
    def address_table_results(page_source_var, mls_number, logger_var):
        try:
            soup = BeautifulSoup(page_source_var, 'html.parser')
            table = soup.find('table', {"class": "df-table nomin mart0", "id": "search-help-table"})
            main_table = table.find('tbody')
            all_rows = main_table.find_all('tr')

            assert len(all_rows) > 0, f'There were no MLS results found. MLS#:{mls_number}'
        except AssertionError as AE:
            logger_var.info(f'{AE}')

            return AE
        else:
            return all_rows